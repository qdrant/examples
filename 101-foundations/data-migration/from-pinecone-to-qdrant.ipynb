{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fce24f0-9a44-483f-8e7e-0d7f76bdd35b",
   "metadata": {},
   "source": [
    "# Migrating Data From Pinecone to Qdrant\n",
    "\n",
    "In this notebook, you will migrate your data into [Qdrant](https://qdrant.to/cloud) from another vector database. \n",
    "You will use [Vector-io](https://github.com/AI-Northstar-Tech/vector-io), a library that makes it easy to migrate, transform, and manage your data across different vector databases. \n",
    "\n",
    "Vector-io uses a standard format called Vector Dataset Format (VDF). This format ensures consistency in the data structure, regardless of the destination database. \n",
    "\n",
    "To illustrate, let's consider a Pinecone index that contains several data from a [PubMed dataset](https://huggingface.co/datasets/llamafactory/PubMedQA) generated using the 1536-dimensional OpenAI \"text-embedding-3-small\" embedding model.\n",
    "\n",
    "![\"Pinecone\"](imgs/pinecone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec5a9d",
   "metadata": {},
   "source": [
    "## Initialize the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe03c97-8072-4cf3-8784-2c167a06febd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380059e7-af8e-4314-aea7-32e600dbfc33",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e15975f-2ddd-45ad-891e-4045026c709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the question based on the following con...</td>\n",
       "      <td>Question: Is naturopathy as effective as conve...</td>\n",
       "      <td>Naturopathy appears to be an effective alterna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the question based on the following con...</td>\n",
       "      <td>Question: Can randomised trials rely on existi...</td>\n",
       "      <td>Routine data have the potential to support hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answer the question based on the following con...</td>\n",
       "      <td>Question: Is laparoscopic radical prostatectom...</td>\n",
       "      <td>The results of our non-randomized study show t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Answer the question based on the following con...</td>\n",
       "      <td>Question: Does bacterial gastroenteritis predi...</td>\n",
       "      <td>Symptoms consistent with IBS and functional di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Answer the question based on the following con...</td>\n",
       "      <td>Question: Is early colonoscopy after admission...</td>\n",
       "      <td>No significant association is apparent between...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Answer the question based on the following con...   \n",
       "1  Answer the question based on the following con...   \n",
       "2  Answer the question based on the following con...   \n",
       "3  Answer the question based on the following con...   \n",
       "4  Answer the question based on the following con...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Question: Is naturopathy as effective as conve...   \n",
       "1  Question: Can randomised trials rely on existi...   \n",
       "2  Question: Is laparoscopic radical prostatectom...   \n",
       "3  Question: Does bacterial gastroenteritis predi...   \n",
       "4  Question: Is early colonoscopy after admission...   \n",
       "\n",
       "                                              output  \n",
       "0  Naturopathy appears to be an effective alterna...  \n",
       "1  Routine data have the potential to support hea...  \n",
       "2  The results of our non-randomized study show t...  \n",
       "3  Symptoms consistent with IBS and functional di...  \n",
       "4  No significant association is apparent between...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"llamafactory/PubMedQA\", split=\"train\")\n",
    "data = data.to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb934fe-2e4b-4732-be19-846241a079bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 1000\n",
    "OUTPUT = \"output\"\n",
    "subset_data = data.head(MAX_ROWS)\n",
    "\n",
    "chunks = subset_data[OUTPUT].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05804d4c-cfb8-47ac-a97e-e561398ce7df",
   "metadata": {},
   "source": [
    "## Create a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60881e8b-21ea-4d57-b46b-a990ba2feb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1afb30-26b5-49ef-a17a-5c54e007da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "pc.create_index(\n",
    "    name=\"pubmed\",\n",
    "    dimension=1536,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=os.getenv(\"PINECONE_CLOUD\"), region=os.getenv(\"PINECONE_REGION\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9409db2c-0116-40f3-b681-f6a48dae4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set embedding model\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "index = pc.Index(\"pubmed\")\n",
    "\n",
    "\n",
    "def embed(docs: list[str]) -> list[list[float]]:\n",
    "    res = openai.embeddings.create(input=docs, model=\"text-embedding-3-small\")\n",
    "    doc_embeds = [r.embedding for r in res.data]\n",
    "    return doc_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94e118a-2ed3-435b-8c9b-51cbccb75dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50774cdbf12a4d2a9e3511e6b8bc0172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upsert data to index\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    i_end = min(len(chunks), i + batch_size)\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    metadatas = [{\"text\": chunk} for chunk in chunks[i:i_end]]\n",
    "    embeds = embed(chunk for chunk in chunks[i:i_end])\n",
    "    records = list(zip(ids, embeds, metadatas))\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae836ceb-1f46-49fb-a546-179a0fe97cdf",
   "metadata": {},
   "source": [
    "## Migrate from Pinecone to Qdrant\n",
    "\n",
    "First you must install the library:\n",
    "```shell\n",
    "$ pip install vdf-io\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3489d8-94f7-45c2-9c9c-02b6f4c56f5e",
   "metadata": {},
   "source": [
    "### Export Data From Pinecone\n",
    "\n",
    "```shell\n",
    "$ export_vdf pinecone --serverless -c aws --region us-east-1 -i pubmed --namespace \"\"\n",
    "Exporting index 'pubmed'\n",
    "Iterating namespace ''\n",
    "Collected 1000 IDs using list_points with implicit pagination.\n",
    "Fetching namespaces: 100%|████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.52s/it]\n",
    "Final Step: Fetching vectors: 2000it [00:04, 470.57it/s]\n",
    "Exporting pubmed: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.29s/it]\n",
    "{\n",
    "    \"version\": \"0.1.246\",\n",
    "    \"file_structure\": [\n",
    "        \"vdf_20240510_001325_88ae5/pubmed/i1.parquet/1.parquet\",\n",
    "        \"vdf_20240510_001325_88ae5/VDF_META.json\"\n",
    "    ],\n",
    "    \"author\": \"infoslack\",\n",
    "    \"exported_from\": \"pinecone\",\n",
    "    \"indexes\": {\n",
    "        \"pubmed\": [\n",
    "            {\n",
    "                \"namespace\": \"\",\n",
    "                \"index_name\": \"pubmed\",\n",
    "                \"total_vector_count\": 1000,\n",
    "                \"exported_vector_count\": 1000,\n",
    "                \"dimensions\": 1536,\n",
    "                \"model_name\": \"NOT_PROVIDED\",\n",
    "                \"model_map\": null,\n",
    "                \"vector_columns\": [\n",
    "                    \"vector\"\n",
    "                ],\n",
    "                \"data_path\": \"pubmed/i1.parquet\",\n",
    "                \"metric\": \"Cosine\",\n",
    "                \"index_config\": null,\n",
    "                \"schema_dict_str\": \"id: string\\nvector: list<element: double>\\n  child 0, element: double\\ntext: string\\n-- schema metadata --\\npandas: '{\\\"index_columns\\\": [{\\\"kind\\\": \\\"range\\\", \\\"name\\\": null, \\\"start\\\": 0, \\\"' + 592\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"exported_at\": \"2024-05-10T00:13:31.858158-03:00\",\n",
    "    \"id_column\": null\n",
    "}\n",
    "Export to disk completed. Exported to: vdf_20240509_145419_88ae5/\n",
    "Time taken to export data:  00:00:06\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19201b3-76ec-42e6-bf95-b78cb9b2c973",
   "metadata": {},
   "source": [
    "### Import Data to Qdrant\n",
    "\n",
    "```shell\n",
    "$ import_vdf qdrant -u $QDRANT_HOST\n",
    "\n",
    "Enter the directory of vector dataset to be imported: vdf_20240509_145419_88ae5\n",
    "ImportVDB initialized successfully.\n",
    "Importing data for index 'pubmed'\n",
    "/Users/infoslack/Projects/vector-migration/vdf_20240509_145419_88ae5/pubmed/i1.parquet/1.parquet read successfully. len(df)=1000 rows\n",
    "Extracting vectors: 100%|█████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6349.32it/s]\n",
    "Metadata was parsed to JSON\n",
    "Uploading points in batches of 64 in 5 threads: 100%|██████████████████████████████████████| 1000/1000 [00:03<00:00, 280.44it/s]\n",
    "Iterating parquet files: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.14s/it]\n",
    "Index 'pubmed' has 1000 vectors after import\n",
    "1000 vectors were imported\n",
    "Importing namespaces: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.55s/it]\n",
    "Importing indexes: 100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.55s/it]\n",
    "Data import completed successfully.\n",
    "Time taken: 5.62 seconds\n",
    "```\n",
    "\n",
    "### Verify Data Migration \n",
    "\n",
    "![\"Qdrant Cloud\"](imgs/qdrant.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ff7ad-8d09-4b52-89cf-944bb76f75cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
