{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prospective-turner",
   "metadata": {
    "id": "prospective-turner",
    "papermill": {
     "duration": 0.045573,
     "end_time": "2021-04-15T21:06:39.651272",
     "exception": false,
     "start_time": "2021-04-15T21:06:39.605699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extractive Question Answering with Qdrant\n",
    "\n",
    "Welcome to a thrilling journey into the realm of AI! In this notebook, we're going to explore an exciting aspect of Natural Language Processing (NLP) - Extractive Question Answering.\n",
    "\n",
    "Question Answering systems can respond to user queries with precise answers. 'Extractive' means our system will pull the answer directly from a given context, rather than generating new text. It's like having your own personal librarian who knows every book cover to cover and can pull the perfect quote for any question you ask!\n",
    "\n",
    "To make our 'AI Librarian', we will be using three main components:\n",
    "1. **Qdrant**: Powers our performant vector search. It's our magic bookshelf that finds the right book.\n",
    "2. **Retriever Model**: It helps in embedding context passages into numerical representations (vectors) that Qdrant can store and search efficiently.\n",
    "3. **Reader Model**: Once Qdrant finds the most relevant passages for a question, our reader model goes through these passages to extract the precise answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-export",
   "metadata": {
    "id": "terminal-export",
    "papermill": {
     "duration": 0.044413,
     "end_time": "2021-04-15T21:06:39.741951",
     "exception": false,
     "start_time": "2021-04-15T21:06:39.697538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install dependencies\n",
    "\n",
    "Let's get started by installing prerequisite packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-executive",
   "metadata": {
    "id": "expressed-executive",
    "papermill": {
     "duration": 102.376674,
     "end_time": "2021-04-15T21:08:22.165052",
     "exception": false,
     "start_time": "2021-04-15T21:06:39.788378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU datasets==2.12.0 qdrant-client==1.10.1 fastembed==0.3.3 sentence-transformers==2.2.2 torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a1f93-1fbe-4ebe-8282-6e9d96349796",
   "metadata": {
    "id": "1b3a1f93-1fbe-4ebe-8282-6e9d96349796"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849c4e3b-af29-479e-b868-221586050422",
   "metadata": {
    "id": "849c4e3b-af29-479e-b868-221586050422",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad3840",
   "metadata": {
    "id": "29ad3840"
   },
   "source": [
    "## Load and process dataset\n",
    "\n",
    "We'll use the [DuoRC dataset](https://huggingface.co/datasets/duorc), containing questions, plots and answers crowd-sourced from Wikipedia and IMDb movie plots.\n",
    "\n",
    "We generate embeddings for the context passages using the retriever, index them in the Qdrant vector database, and query to retrieve the top k most relevant contexts containing potential answers to our question. We then use the reader model to extract the answers from the returned contexts.\n",
    "\n",
    "We load the dataset into a pandas dataframe. Keep the title and plot columns, and we drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "J250IJeh7NIb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "J250IJeh7NIb",
    "outputId": "dc52f35f-c8c3-4cab-cf2b-d95834501e0a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1748: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n",
      "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/ParaphraseRC-2dfadd51314ddbba/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates: 130245\n",
      "Unique Plots: 9919\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9919,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6056,\n        \"samples\": [\n          \"People I Know\",\n          \"The Devil Bat\",\n          \"Charlie Muffin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plot\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9919,\n        \"samples\": [\n          \"In Paris in 1910, mother cat Duchess and her three kittens, Marie, Berlioz, and Toulouse, live with retired opera diva Madame Adelaide Bonfamille, and her English butler, Edgar. One day while preparing her will with lawyer Georges Hautecourt, Madame declares her fortune to be left to her cats until their deaths, and thereafter to Edgar. Edgar hears this through a speaking tube, and plots to eliminate the cats. Therefore, he sedates the cats by sleeping pills in their food, and enters the countryside to abandon them. There, he is ambushed by two hounds, named Napoleon and Lafayette, and the cats are stranded in the countryside, while Madame Adelaide, Roquefort the mouse, and Frou-Frou the horse discover their absence. In the morning, Duchess meets an alley cat named Thomas O'Malley, who offers to guide her and the kittens to Paris. The group briefly hitchhike in a milk cart before being chased off by the driver. Later, while crossing a railroad trestle, the cats narrowly avoid an oncoming train, but Marie falls into a river and is saved by O'Malley; himself rescued by two English geese, Amelia and Abigail Gabble, who accompany the cats to Paris. Edgar returns to the country to retrieve his possessions from Napoleon and Lafayette, as the only evidence that could incriminate him.\\nTravelling across the rooftops of the city, the cats meet O'Malley's friend Scat Cat and his musicians, who perform the scat song Ev'rybody Wants to Be a Cat. After the band has departed, O'Malley and Duchess converse on a nearby rooftop while the kittens listen at a windowsill. Here, Duchess' loyalty to Madame prompts her to decline O'Malley's proposal of marriage. Duchess and the kittens return to Madame's mansion, but Edgar places them in a sack and prepares to ship them to Timbuktu; whereupon they direct Roquefort to retrieve O'Malley. He does so, and O'Malley returns to the mansion, ordering Roquefort to find Scat Cat and his gang. This done, the alley cats and Frou-Frou fight Edgar, while Roquefort frees Duchess and the kittens. In the end of the fight, Edgar is locked in his own packing-case and sent to Timbuktu himself. Madame Adelaide's will is rewritten to exclude Edgar, with Madame expressing surprise at Edgar\\u00e2\\u0080\\u0099s departure. After adopting O\\u00e2\\u0080\\u0099Malley into the family, Madame establishes a charity foundation housing Paris' stray cats (represented by Scat Cat and his band, who reprise their song).\",\n          \"This article's plot summary may be too long or excessively detailed. Please help improve it by removing unnecessary details and making it more concise. (October 2015) (Learn how and when to remove this template message)\\n17-year-old identical twin sisters Jane (Ashley Olsen) and Roxy Ryan (Mary-Kate Olsen) are completely different and never see eye to eye, and live with their father in a suburban Long Island neighborhood. Over a 24-hour period, the two begrudgingly journey together into the city for Jane, an uptight overachiever, to deliver a speech to qualify for a prestigious college scholarship abroad, and for Roxy, a laid-back punk-rock rebel, to get backstage at a music video shoot so that she can give her demo tape to the group.\\nJane and Roxy board the train into New York but are soon thrown off together after Roxy is found without a ticket. At the station, Jane bumps into Jim (Riley Smith), and they flirt back and forth before he gets on the train. Meanwhile, Roxy becomes unknowingly involved in a shady black-market transaction after an illegal chip device is mistakenly planted in her bag. Bennie Bang (Andy Richter), the man behind the plan, offers Roxy a ride in a swanky limousine and she accepts, dragging Jane along who is reluctant about getting into cars with strangers. He locks them inside but they escape through the sun roof and he chases them into the city subway where they help one another to fight him off.\\nMeanwhile, Max Lomax (Eugene Levy), an overzealous truant officer, is on the hunt to find Roxy after news of her continuously missing school and forging absence letters from her father. Several unlucky incidents occur as they begin their journey such as Jane's heels snapping and being drenched by a hobo's blue slush drink. At the nearest store, Jane realizes she's left her day planner in the limo, which has \\\"her whole life\\\" in it including money and the prompt cards needed her for college speech later that day. To clean up, they break into a posh hotel room and soon receive a phone call from Bennie who threatens to meet him to give the chip back or they won't get the day planner, but before they can leave, they meet Trey (Jared Padalecki), the son of the powerful Senator who's staying at the hotel, and his dog who swallows the chip. They are forced to take the dog with them.\\nThey make their way to their destinations and decide to part ways. Roxy heads to the Simple Plan video shoot being followed by Max, while Jane goes to meet Bennie for an exchange. When he finds out the dog, Ronaldo, has swallowed the chip, he tries to attack Jane who flees from the car and goes to find Roxy. While running from Max and Bennie, the two end up on stage with the band and crowd surf to get away. Trey is also trying to find Roxy who runs into Bennie and gets kidnapped in the trunk of his car. Meanwhile, Jane and Roxy end up in the underground sewer with the dog, with Jane's speech in less than two hours.\\nA little later, they walk into the House Of Bling where Big Shirl (Mary Bond Davis) gives them both a makeover. Max hunts them down and they escape in a cab even when Jane failed her driving test. They accidentally pick up the same man that Roxy spilled her drink on in the train. When they stop, they argue. Jane explains that Roxy has never been there for her and never takes life seriously, and she feels she stopped taking responsibility for anything after their mother died, leaving Jane in charge. Conversely, Roxy believes Jane doesn't need to take control of everything and feels she's been pushed away, since she wasn't even invited to Jane's speech.\\nJane goes to meet Bennie who throws her in the back of a van with Ronaldo and drives her to see his mother who is in charge of the whole operation: they sell and buy illegal pirated DVD's and CD's. Roxy finds Bennie's limo and retrieves Jane's day planner, but finds Trey locked in the trunk. They both rush to the building where Jane is meant to give her speech, while Jane fends off Bennie and escapes once again and then runs into Jim who gives her a ride to the same place. When they arrive, Roxy pretends to be Jane so she can give a speech on time, but drops the prompt cards beforehand and has to make it up on the spot, which confuses the judges. The head judge is Senator Hudson McGill (Darrell Hammond), the man from the train and the taxi, alongside Trey's mother, Senator Anne Lipton. Jane turns up just in time who tries to explain what their day has been like and the reason for why she wasn't there. Suddenly, Max intervenes who tries to arrest Roxy and Bennie appears who tries to kidnap Jane, but they both exploit his illegal doings and he is arrested by Max.\\nKnowing she has no opportunity to give her speech, Jane leaves with Roxy. Outside, Hudson McGill catches up to Jane who found her prompt cards and gives her a college scholarship to Oxford, because she \\\"didn't just want to win, she absolutely refused to fail.\\\"\\nMonths later, Roxy is in the studio recording with her band, watched by Jane, Trey and Jim, who celebrate all together.\",\n          \"This article's plot summary may be too long or excessively detailed. Please help improve it by removing unnecessary details and making it more concise. (October 2015) (Learn how and when to remove this template message)\\nWill Stanton (Alexander Ludwig) is a day away from his fourteenth birthday. As the Stanton children walk home, Miss Greythorne (Frances Conroy), the local mistress of the Manor, and her Butler Merriman Lyon (Ian McShane) invite the siblings to a Christmas party. Later, two farmers, Dawson (James Cosmo) and Old George (Jim Piddock), whom Will does not know, arrive at his house with a large Christmas tree ordered by the family. The farmers know Will\\u00e2\\u0080\\u0099s name, wish him a happy birthday, and predict bad weather despite the clear sky. Will\\u00e2\\u0080\\u0099s birthday is so close to Christmas that everyone in his large family ignores it except for his little sister Gwen (Emma Lockhart), who gives him his only birthday present (a Casio G-Shock Mudman wristwatch). The family has moved from the United States to a small English village and one of his brothers has arrived home for the holidays and displaces Will to the attic. For a Christmas present, Will buys Gwen an enigmatic stone pendant at the local mall. Two suspicious security guards accuse him of shoplifting and take him to their office. Alarmingly, as they question Will under the room's flickering lights, the guards metamorphose into rooks. They attack Will, but he manages to escape, accidentally using his powers for the first time. Will begins to experience more odd incidents and receives a strange and Celtic-looking belt from his oldest brother, Stephen (Jordan J. Dale).\\nAt the Manor Christmas party, Will once again sees Dawson and Old George who seem to know him well. Miss Greythorne and Merriman debate about when and how to approach Will about his destiny. Maggie Barnes (Amelia Warner), an attractive local girl appears at the party and Will becomes upset when one of his older brothers approaches her and begins chatting to her. Will leaves the Manor, and an ominous figure mounted on a white horse and accompanied by dogs chases Will. As the ominous figure prepares to kill Will, who is currently no match for him, Miss Greythorne, Merriman, Dawson, and Old George suddenly appear and save Will. Merriman names the threatening figure as The Rider (Christopher Eccleston), who warns them all that in five days' time his power \\u00e2\\u0080\\u0093 The Dark \\u00e2\\u0080\\u0093 will rise. The four adults are the last of the Old Ones \\u00e2\\u0080\\u0093 ancient warriors who serve The Light \\u00e2\\u0080\\u0093 and take Will on a walk through time and space to a place called the Great Hall, which in the present day is the church the Stantons attend. Will is the last of the Old Ones to have been born: he is the seventh son of a seventh son whose power begins to ascend on his fourteenth birthday, though Will disputes this idea because he believes he is the sixth son. Will is The Seeker: the sign-seeker who must locate six Signs whose possession will grant The Light power over The Dark. The Rider is also seeking them. Will returns home to his attic room and falls and twists his ankle. The doctor who calls is The Rider in disguise but he is recognized by Will. The Rider demonstrates his powers on Will\\u00e2\\u0080\\u0099s ankle by alternately healing it and making it much worse before restoring it to its injured state; he offers Will the chance to have any desire he wants fulfilled in exchange for giving him the signs. Will discovers he has a lost twin brother named Tom, who, as a baby, mysteriously disappeared one night and was never found. Merriman instructs Will on his powers, which include sensing the Signs, summoning superhuman strength, commanding light and fire, telekinesis, stepping through time, and the unique knowledge to decipher an ancient text in the Book of Gramarye. Unfortunately, Will learns he can't fly, a power he wanted.\\nWill returns to The Great Hall, and learns the form each sign will take. Will reveals the first sign within Gwen\\u00e2\\u0080\\u0099s pendant. As the sign-seeker, Will travels through time to find the next four signs. The Rider enlists a mysterious figure to help him get the signs from Will. When Will's brother invites Maggie to their home, she reveals some of her powers to Will. Will reveals his affections for her, saying he felt an instant connection with her. He tells her he has been thinking of her constantly. The Rider also tricks Will's older brother Max, using his magic to partially control him. The spell over Max is finally broken when Will uses his great strength to give Max a concussion. By the fifth day, The Dark that The Rider commands has now gained tremendous power and begins to attack the village with a terrible blizzard. Will locates the fifth sign but without the sixth sign, the Dark continues to rise. Maggie is revealed to be the mysterious witch helping the Rider in exchange for immortal youth. She is betrayed by him (for failing to get ANY of the signs) when she fails to get the fifth sign and ages rapidly, disintegrating into a flood of water while trying to steal them from Will. The Old Ones and Will seek sanctuary in the Great Hall, where the Rider cannot enter unless invited. However, The Rider's final trick (impersonating the voices of Will's mother and father, as well as Gwen) gains him access to The Great Hall. The Rider reveals that he has trapped Tom, whom The Rider mistook for The Seeker and kidnapped, within a glass sphere (and apparently took care of all these years). He sends Will into an evil dark cloud. As he enters, Will solves the riddle of the sixth sign: he himself is the sixth sign. With all six signs identified The Rider cannot touch nor harm Will. Using his power over the dark, Will banishes both The Rider \\u00e2\\u0080\\u0093 imprisoning the evil figure within one of his own glass spheres \\u00e2\\u0080\\u0093 and The Dark. The sphere disappears into murky water. Will and Tom are reunited and return to their family, who are shocked to see Tom.\\n\\nThe Six Signs\\nThe signs that Will found, in the order he found them, were:\\n\\nInside a pendant Will bought for his little sister Gwen in a mall\\nJust before the black plague, inside a skull's mouth under a church \\u00e2\\u0080\\u0093 the skull belonging to the creator of the signs \\u00e2\\u0080\\u0093 at the beginning of the 14th Century\\nOn a shield some time in the past when Vikings attacked the village. He trades the watch Gwen gave him for his birthday for the sign.\\nOn one of the feathers of \\\"The Champion\\\" from 1690\\nUnderwater in the manor when it was flooded, at the time of Maggie's demise\\nWill's soul\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-849355a9-67d9-404f-87c4-467862b6417b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Noriko's Dinner Table</td>\n",
       "      <td>The film starts on December 12th, 2001 with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gutterballs</td>\n",
       "      <td>A brutally sadistic rape leads to a series of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>An Innocent Man</td>\n",
       "      <td>Jimmie Rainwood (Tom Selleck) is a respected m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana (Kelly L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-849355a9-67d9-404f-87c4-467862b6417b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-849355a9-67d9-404f-87c4-467862b6417b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-849355a9-67d9-404f-87c4-467862b6417b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-86d73330-3d74-4810-b13b-8095243fc91b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86d73330-3d74-4810-b13b-8095243fc91b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-86d73330-3d74-4810-b13b-8095243fc91b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0               Ghosts of Mars   \n",
       "15       Noriko's Dinner Table   \n",
       "34                 Gutterballs   \n",
       "83             An Innocent Man   \n",
       "105  The Sorcerer's Apprentice   \n",
       "\n",
       "                                                  plot  \n",
       "0    Set in the second half of the 22nd century, Ma...  \n",
       "15   The film starts on December 12th, 2001 with a ...  \n",
       "34   A brutally sadistic rape leads to a series of ...  \n",
       "83   Jimmie Rainwood (Tom Selleck) is a respected m...  \n",
       "105  Every hundred years, the evil Morgana (Kelly L...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the duorc dataset into a pandas dataframe\n",
    "df = load_dataset(\n",
    "    \"duorc\", \"ParaphraseRC\", split=\"train\", ignore_verifications=True\n",
    ").to_pandas()\n",
    "df = df[[\"title\", \"plot\"]]  # select only title and plot column\n",
    "print(f\"Before removing duplicates: {len(df)}\")\n",
    "\n",
    "df = df.drop_duplicates(\n",
    "    subset=\"plot\"\n",
    ")  # drop rows containing duplicate plot passages, if any\n",
    "print(f\"Unique Plots: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bbcb57",
   "metadata": {
    "id": "57bbcb57"
   },
   "source": [
    "## Initialize Qdrant client\n",
    "The Qdrant collection stores vector representations of our context passages which we can retrieve using another vector (query vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "092d1e71",
   "metadata": {
    "id": "092d1e71",
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57846b65-ce51-43a8-981b-ca613ff5bb07",
   "metadata": {
    "id": "57846b65-ce51-43a8-981b-ca613ff5bb07",
    "tags": []
   },
   "source": [
    "## Create collection\n",
    "\n",
    "Now we create a new collection called `extractive-question-answering` â€” we can name the collection anything we want.\n",
    "\n",
    "We specify the metric type as \"cosine\" and dimension or size as 384 because the retriever we use to generate context embeddings is optimized for cosine similarity and outputs 384-dimension vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3206184",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3206184",
    "outputId": "ba9da097-22ea-4d68-f981-20aa0eec2506",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n",
      "collections=[CollectionDescription(name='extractive-question-answering')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-3a672cf6b8d1>:8: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"extractive-question-answering\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "print(collections)\n",
    "\n",
    "# only create collection if it doesn't exist\n",
    "if collection_name not in [c.name for c in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "collections = client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84a3e5",
   "metadata": {
    "id": "6e84a3e5"
   },
   "source": [
    "## Initialize retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oZzhGS1Lpj0g",
   "metadata": {
    "id": "oZzhGS1Lpj0g"
   },
   "source": [
    "Next, we need to initialize our retriever. The retriever will mainly do two things:\n",
    "\n",
    "- Generate embeddings for all context passages (context vectors/embeddings)\n",
    "- Generate embeddings for our questions (query vector/embedding)\n",
    "\n",
    "The retriever will generate embeddings in a way that the questions and context passages containing answers to our questions are nearby in the vector space. We can use cosine similarity to calculate the similarity between the query and context embeddings to find the context passages that contain potential answers to our question.\n",
    "\n",
    "### Embedding model\n",
    "\n",
    "We will use a SentenceTransformer model named `BAAI/bge-small-en-v1.5` designed for semantic search .It's also quite competitive on two embedding and retrieval benchmarks: [MTEB](https://github.com/embeddings-benchmark/mteb) and [BEIR](arxiv.org/abs/2104.08663)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a85bb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "03863d87ccda4a998eadf8a54f5d2e09",
      "1a8138c6c0a7493ba6a81650d18d47d1",
      "15f6f80ac7f847978d61ea8c42708a8e",
      "999d2924a7994ad7ae9fd86d157a7c1d",
      "9f44091f2ac24f6e8062ac3f03997134",
      "9b4f69bc3a614b0482b4e7453f39ef10",
      "6a0e61da5c2d4462a1488466f2c211d8",
      "d96e08dc831344adbe2e84e721248158",
      "2793cc7c66f74f32bedfc976384b3184",
      "116d18a1e16d4c8c85ce9e95bc8eef15",
      "23fe8d3cad8f493d9fbe1d41acb52939"
     ]
    },
    "id": "31a85bb3",
    "outputId": "3a7e5dda-3598-488d-acdc-a6648d758dfe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03863d87ccda4a998eadf8a54f5d2e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fastembed.text.text_embedding.TextEmbedding at 0x7f3dd625dc30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hgy7AagJtO_p",
   "metadata": {
    "id": "Hgy7AagJtO_p"
   },
   "source": [
    "## Generate Embeddings -> Store in Qdrant\n",
    "\n",
    "Next, we need to generate embeddings for the context passages. We will use the `retriever.encode` for that.\n",
    "\n",
    "When passing the documents to Qdrant, we need an:\n",
    "1. id (a unique integer value),\n",
    "2. context embedding, and\n",
    "3. payload for each document representing context passages in the dataset. The payload is a dictionary containing data relevant to our embeddings, such as the title, plot etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17824ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b84a5bd9b8134ea085474544f2df30f2",
      "a6786f3f54384615b9ccbd840de85219",
      "c9417a0ebe014209bc9c5748f5630bb6",
      "32ae999903ba4ff8b3bf51bbdce32b47",
      "f9c7682995534789bfc8f8d1a10a3e08",
      "70dabb8ae4954abfbc31187facf6eedb",
      "9b1a2b2f85ea411186ff178b84f3e18c",
      "c379764c41d143b5918057b95c691598",
      "1ed1c9317e734303ac71a3306bf7020c",
      "7e5dccf60c4f42bc8ef6452897298f44",
      "1135a98445954608a9abea5c7f36f537"
     ]
    },
    "id": "a17824ef",
    "outputId": "be75fd10-8a93-4833-b16b-4c4f4864fe7a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84a5bd9b8134ea085474544f2df30f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "for index in tqdm(range(0, len(df), batch_size)):\n",
    "    i_end = min(index + batch_size, len(df))  # find end of batch\n",
    "    batch = df.iloc[index:i_end]  # extract batch\n",
    "    emb = list(retriever.embed(batch[\"plot\"].tolist()))  # generate embeddings for batch\n",
    "    emb = [e.tolist() for e in emb]\n",
    "    meta = batch.to_dict(orient=\"records\")  # get metadata\n",
    "    ids = list(range(index, i_end))  # create unique IDs\n",
    "\n",
    "    # upsert to qdrant\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=models.Batch(ids=ids, vectors=emb, payloads=meta),\n",
    "    )\n",
    "\n",
    "collection_vector_count = client.get_collection(\n",
    "    collection_name=collection_name\n",
    ").points_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n",
    "assert collection_vector_count == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HgdiLCz5ynOk",
   "metadata": {
    "id": "HgdiLCz5ynOk"
   },
   "source": [
    "## Initialize Reader\n",
    "\n",
    "We use the `bert-large-uncased-whole-word-masking-finetuned-squad` model from the HuggingFace model hub as our reader model. This is finetuned on the [SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). It is trained to extract an answer from a given context. This special mechanism is why we can use this model to extract answers from our context passages.\n",
    "\n",
    "This is our (encoder) component which uses the contexts to extract an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hg9XTDkIJzH_",
   "metadata": {
    "id": "hg9XTDkIJzH_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(\"question-answering\", model=model_name, tokenizer=model_name)\n",
    "print(reader.model, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d89d6",
   "metadata": {
    "id": "e14d89d6"
   },
   "source": [
    "Now all the components we need are ready. Let's write some helper functions to execute our queries. The `get_relevant_plot` function retrieves the context embeddings containing answers to our question from the Qdrant collection, and the `extract_answer` function extracts the answers from these context passages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae27f6-e0a6-42a2-8da9-3e3c969336b3",
   "metadata": {
    "id": "fdae27f6-e0a6-42a2-8da9-3e3c969336b3"
   },
   "source": [
    "## Get context\n",
    "\n",
    "The `get_relevant_plot()` function is your librarian to the vast universe of stories stored in Qdrant.\n",
    "\n",
    "When you have a question or need a specific story (plot), you tell this guide your question and how many top matches you want. The guide then translates your question into a language Qdrant understands, finds the best matching stories in Qdrant's massive library, and delivers you the titles and contents of these matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lyYaY3QEQiHZ",
   "metadata": {
    "id": "lyYaY3QEQiHZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_relevant_plot(question: str, top_k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the relevant plot for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): Top K results to return\n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query = next(\n",
    "            retriever.query_embed(question)\n",
    "        ).tolist()  # generate embeddings for the question\n",
    "\n",
    "        result = client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            query=encoded_query,\n",
    "            limit=top_k,\n",
    "        ).points  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "            [x.payload[\"title\"], x.payload[\"plot\"]] for x in result\n",
    "        ]  # extract title and payload from result\n",
    "        return context\n",
    "\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048dfe1-0a0a-4b01-a9ee-79860827b970",
   "metadata": {
    "id": "c048dfe1-0a0a-4b01-a9ee-79860827b970"
   },
   "source": [
    "## Extracting an answer\n",
    "\n",
    "Here is how the engine operates:\n",
    "\n",
    "1. The central part of the function is `extract_answer`. Qdrant processes your question and retrieves all related context.\n",
    "\n",
    "2. All related context is processed via the `reader`, which looks at each piece of context and extracts an answer that best fits your question.\n",
    "\n",
    "3. The function sorts all answers by confidence score, with the top score at the front. Each answer has a title in order to provide context.\n",
    "\n",
    "4. The result is a sorted list of potential answers, their confidence scores and associated titles.\n",
    "\n",
    "That's it! All you have to do is put in a question, and wait for an ordered list of the best possible answers. The advantage of this engine is that it also tells you where the answer came from and how confident it is about the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Dc9VYOiUQA7B",
   "metadata": {
    "id": "Dc9VYOiUQA7B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_answer(question: str, context: List[str]):\n",
    "    \"\"\"\n",
    "    Extract the answer from the context for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): _description_\n",
    "        context (list[str]): _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for c in context:\n",
    "        # feed the reader the question and contexts to extract answers\n",
    "        answer = reader(question=question, context=c[1])\n",
    "\n",
    "        # add the context to answer dict for printing both together, we print only first 500 characters of plot\n",
    "        answer[\"title\"] = c[0]\n",
    "        results.append(answer)\n",
    "\n",
    "    # sort the result based on the score from reader model\n",
    "    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i in range(len(sorted_result)):\n",
    "        print(f\"{i+1}\", end=\" \")\n",
    "        print(\n",
    "            \"Answer: \",\n",
    "            sorted_result[i][\"answer\"],\n",
    "            \"\\n  Title: \",\n",
    "            sorted_result[i][\"title\"],\n",
    "            \"\\n  score: \",\n",
    "            sorted_result[i][\"score\"],\n",
    "        )\n",
    "\n",
    "\n",
    "question = \"In the movie 3 Idiots, what is the name of the college where the main characters Rancho, Farhan, and Raju study\"\n",
    "context = get_relevant_plot(question, top_k=1)\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heKNVbWQ_LtC",
   "metadata": {
    "id": "heKNVbWQ_LtC"
   },
   "source": [
    "As we can see, the retriever is working fine and gets us the context passage that contains the answer to our question. Now let's use the reader to extract the exact answer from the context passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DQ4GWdbMSjPl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ4GWdbMSjPl",
    "outputId": "73eabb60-e42a-4983-ed7f-a90e51eb9781",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  Imperial College of Engineering \n",
      "  Title:  Three Idiots \n",
      "  score:  0.9049272537231445\n"
     ]
    }
   ],
   "source": [
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fMD_ABuDAyhN",
   "metadata": {
    "id": "fMD_ABuDAyhN"
   },
   "source": [
    "The reader model predicted with 90% accuracy the correct answer as seen from the context passage. Let's run few more queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_4NRgV4mGWoj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4NRgV4mGWoj",
    "outputId": "4140fe3e-32b9-42ad-8631-303d07df6dda",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  . \n",
      "  Title:  Harry Potter and the Half-Blood Prince \n",
      "  score:  0.15585105121135712\n"
     ]
    }
   ],
   "source": [
    "question = \"Who hates Harry Potter?\"\n",
    "context = get_relevant_plot(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ad3e9",
   "metadata": {
    "id": "5c8ad3e9"
   },
   "source": [
    "This might look like a simple question, but it's actually a pretty tough one for our model. The answer is not explicitly mentioned in the context passage, but the model still tries to extract the answer from the context passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9e2ee",
   "metadata": {
    "id": "29e9e2ee",
    "outputId": "690a699d-8772-4439-eeb0-27b2e01864f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  Lord Voldemort \n",
      "  Title:  Harry Potter and the Philosopher's Stone \n",
      "  score:  0.9568217992782593\n"
     ]
    }
   ],
   "source": [
    "question = \"Who wants to kill Harry Potter?\"\n",
    "context = get_relevant_plot(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juXlctWgJgMF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juXlctWgJgMF",
    "outputId": "e25d311a-5ff5-4b5a-f1f2-f07bf606a076",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  rock hammer \n",
      "  Title:  The Shawshank Redemption \n",
      "  score:  0.8666210770606995\n"
     ]
    }
   ],
   "source": [
    "question = \"In the movie The Shawshank Redemption, what was the item that Andy Dufresne used to escape from Shawshank State Penitentiary?\"\n",
    "context = get_relevant_plot(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OhCgeny_BVno",
   "metadata": {
    "id": "OhCgeny_BVno"
   },
   "source": [
    "Let's run another question. This time for top 3 context passages from the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b278ddb-6c8b-45c3-9640-53772fff2e9a",
   "metadata": {
    "id": "4b278ddb-6c8b-45c3-9640-53772fff2e9a",
    "outputId": "272b5e2f-3e6b-47b7-b0a7-6c4d846cbcb0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  Soviet agents \n",
      "  Title:  Tinker, Tailor, Soldier, Spy \n",
      "  score:  0.7920866012573242\n",
      "2 Answer:  Gila \n",
      "  Title:  Our Man Flint \n",
      "  score:  0.12037214636802673\n",
      "3 Answer:  Gabriel's assassins \n",
      "  Title:  Live Free or Die Hard \n",
      "  score:  0.06259559094905853\n"
     ]
    }
   ],
   "source": [
    "question = \"who killed the spy\"\n",
    "context = get_relevant_plot(question, top_k=3)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdaafe",
   "metadata": {
    "id": "10fdaafe"
   },
   "source": [
    "### Cleaning up\n",
    "\n",
    "We delete the collection from Qdrant and close the connection to the database. This is important to do, otherwise the collection will keep running in the background and consume resources. In a production environment, you would not want to do this. Here, we are mentioning this for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722ca75-ebdf-4c2a-875a-48c7da9a66aa",
   "metadata": {
    "id": "3722ca75-ebdf-4c2a-875a-48c7da9a66aa",
    "outputId": "a75f8fc3-710e-43db-f4ff-2277c6503520",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=collection_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "question_answering.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 333.240754,
   "end_time": "2021-04-15T21:12:11.363566",
   "environment_variables": {},
   "exception": null,
   "input_path": "/notebooks/question_answering/question_answering.ipynb",
   "output_path": "/notebooks/tmp/question_answering/question_answering.ipynb",
   "parameters": {},
   "start_time": "2021-04-15T21:06:38.122812",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fe10bf018ef3e697f9035d60bf60847932a12bface18908407fd371fe880db9"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03863d87ccda4a998eadf8a54f5d2e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a8138c6c0a7493ba6a81650d18d47d1",
       "IPY_MODEL_15f6f80ac7f847978d61ea8c42708a8e",
       "IPY_MODEL_999d2924a7994ad7ae9fd86d157a7c1d"
      ],
      "layout": "IPY_MODEL_9f44091f2ac24f6e8062ac3f03997134"
     }
    },
    "1135a98445954608a9abea5c7f36f537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "116d18a1e16d4c8c85ce9e95bc8eef15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15f6f80ac7f847978d61ea8c42708a8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d96e08dc831344adbe2e84e721248158",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2793cc7c66f74f32bedfc976384b3184",
      "value": 5
     }
    },
    "1a8138c6c0a7493ba6a81650d18d47d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b4f69bc3a614b0482b4e7453f39ef10",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6a0e61da5c2d4462a1488466f2c211d8",
      "value": "Fetchingâ€‡5â€‡files:â€‡100%"
     }
    },
    "1ed1c9317e734303ac71a3306bf7020c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23fe8d3cad8f493d9fbe1d41acb52939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2793cc7c66f74f32bedfc976384b3184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32ae999903ba4ff8b3bf51bbdce32b47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e5dccf60c4f42bc8ef6452897298f44",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1135a98445954608a9abea5c7f36f537",
      "value": "â€‡1/155â€‡[00:38&lt;1:38:48,â€‡38.50s/it]"
     }
    },
    "6a0e61da5c2d4462a1488466f2c211d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70dabb8ae4954abfbc31187facf6eedb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e5dccf60c4f42bc8ef6452897298f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "999d2924a7994ad7ae9fd86d157a7c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_116d18a1e16d4c8c85ce9e95bc8eef15",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23fe8d3cad8f493d9fbe1d41acb52939",
      "value": "â€‡5/5â€‡[00:00&lt;00:00,â€‡233.15it/s]"
     }
    },
    "9b1a2b2f85ea411186ff178b84f3e18c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b4f69bc3a614b0482b4e7453f39ef10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f44091f2ac24f6e8062ac3f03997134": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6786f3f54384615b9ccbd840de85219": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70dabb8ae4954abfbc31187facf6eedb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9b1a2b2f85ea411186ff178b84f3e18c",
      "value": "â€‡â€‡1%"
     }
    },
    "b84a5bd9b8134ea085474544f2df30f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6786f3f54384615b9ccbd840de85219",
       "IPY_MODEL_c9417a0ebe014209bc9c5748f5630bb6",
       "IPY_MODEL_32ae999903ba4ff8b3bf51bbdce32b47"
      ],
      "layout": "IPY_MODEL_f9c7682995534789bfc8f8d1a10a3e08"
     }
    },
    "c379764c41d143b5918057b95c691598": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9417a0ebe014209bc9c5748f5630bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c379764c41d143b5918057b95c691598",
      "max": 155,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ed1c9317e734303ac71a3306bf7020c",
      "value": 1
     }
    },
    "d96e08dc831344adbe2e84e721248158": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9c7682995534789bfc8f8d1a10a3e08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
