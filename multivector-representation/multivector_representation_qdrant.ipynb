{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbpC0h61B57z"
   },
   "source": [
    "# Multivector Representation Example\n",
    "\n",
    "This example demonstrates how to use Qdrant's multi-vector search capabilities with both dense and late-interaction (ColBERT-style) embeddings for retrieval and reranking.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qdrant/examples/blob/master/multivector-representation/multivector_representation_qdrant.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Connects to a Qdrant vector database instance.\n",
    "- Loads two embedding models:\n",
    "  - Dense embedding model (e.g., `BAAI/bge-small-en`)\n",
    "  - Late interaction embedding model (e.g., `colbert-ir/colbertv2.0`)\n",
    "- Indexes documents with both dense and ColBERT embeddings.\n",
    "- Performs a search: first retrieves candidates with the dense vector, then reranks them using the ColBERT multivector.\n",
    "- Returns the top reranked results.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.8+\n",
    "- Qdrant client\n",
    "- fastembed\n",
    "\n",
    "Install dependencies:\n",
    "```bash\n",
    "pip install qdrant-client[fastembed]>=1.14.2\n",
    "```\n",
    "\n",
    "You also need a running Qdrant instance (default: `http://localhost:6333`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTCVxIqLCZ4X"
   },
   "source": [
    "## Usage\n",
    "\n",
    "Let’s demonstrate how to effectively use multivectors using FastEmbed, which wraps ColBERT into a simple API.\n",
    "\n",
    "Install FastEmbed and Qdrant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u5NzdfxYFEjV"
   },
   "outputs": [],
   "source": [
    "!pip install \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cx7BkSjCcCp"
   },
   "source": [
    "# 1. Prepare your Qdrant server\n",
    "\n",
    "Ensure that Qdrant is running and create a client:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W8jlXYzMCZnd"
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9mJwLrGC5O5"
   },
   "source": [
    "# 2. Load embedding models\n",
    "\n",
    "Next, define your embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GkCnxUcYCoGz"
   },
   "outputs": [],
   "source": [
    "dense_model = \"BAAI/bge-small-en\" # Any dense model\n",
    "colbert_model = \"colbert-ir/colbertv2.0\"  # Late interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4D7FKmMC7Q1"
   },
   "source": [
    "# 3. Example documents and query\n",
    "\n",
    "Let's create some sample documents for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uKDZhjhEC7BM"
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Artificial intelligence is used in hospitals for cancer diagnosis and treatment.\",\n",
    "    \"Self-driving cars use AI to detect obstacles and make driving decisions.\",\n",
    "    \"AI is transforming customer service through chatbots and automation.\"\n",
    "]\n",
    "query_text = \"How does AI help in medicine?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPvOzPd2DOhH"
   },
   "source": [
    "# 4. Generate embeddings\n",
    "\n",
    "Next, encode your documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OB4ULlqiDMPy"
   },
   "outputs": [],
   "source": [
    "dense_documents = [\n",
    "    models.Document(text=doc, model=dense_model)\n",
    "    for doc in documents\n",
    "]\n",
    "dense_query = models.Document(text=query_text, model=dense_model)\n",
    "\n",
    "colbert_documents = [\n",
    "    models.Document(text=doc, model=colbert_model)\n",
    "    for doc in documents\n",
    "]\n",
    "colbert_query = models.Document(text=query_text, model=colbert_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMSgat47DQhw"
   },
   "source": [
    "# 5. Create collection with dense + multivector configuration\n",
    "\n",
    "Then create a Qdrant collection with both vector types. Note that we leave indexing on for the dense vector but turn it off for the colbert vector that will be used for reranking.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "omceU-jLDSRA",
    "outputId": "5df34e07-0910-4397-ca16-6b264db6094b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"dense_multivector_search_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\n",
    "        \"dense\": models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE\n",
    "            # Leave HNSW indexing ON for dense\n",
    "        ),\n",
    "        \"colbert\": models.VectorParams(\n",
    "            size=128,\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0)  #  Disable HNSW for reranking\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wL_aHsuDX1N"
   },
   "source": [
    "# 6. Upload documents with both dense and multivector embeddings\n",
    "\n",
    "Now upload the vectors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AcsgFPpoDUgP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = [\n",
    "    models.PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            \"dense\": dense_documents[i],\n",
    "            \"colbert\": colbert_documents[i]\n",
    "        },\n",
    "        payload={\"text\": documents[i]}\n",
    "    )\n",
    "    for i in range(len(documents))\n",
    "]\n",
    "client.upsert(collection_name=collection_name, points=points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epSrqjRVDb4n"
   },
   "source": [
    "# 7. Search using dense vector (prefetch), then rerank with multivector in one query\n",
    "Now let’s run a search:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ryqfmNphDdtD"
   },
   "outputs": [],
   "source": [
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    prefetch=models.Prefetch(\n",
    "        query=dense_query,\n",
    "        using=\"dense\",\n",
    "    ),\n",
    "    query=colbert_query,\n",
    "    using=\"colbert\",\n",
    "    limit=3,\n",
    "    with_payload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOZmh1LxDhCQ"
   },
   "source": [
    "# 8. Display final reranked results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gmencAsYDib9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points=[ScoredPoint(id=1, version=0, score=18.812855, payload={'text': 'Self-driving cars use AI to detect obstacles and make driving decisions.'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=2, version=0, score=18.604212, payload={'text': 'AI is transforming customer service through chatbots and automation.'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=0, version=0, score=14.95095, payload={'text': 'Artificial intelligence is used in hospitals for cancer diagnosis and treatment.'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dense vector retrieves the top candidates quickly.\n",
    "- The Colbert multivector reranks them using token-level MaxSim with fine-grained precision.\n",
    "- Returns the top 3 results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "Multivector search is one of the most powerful features of a vector database when used correctly. With this functionality in Qdrant, you can:\n",
    "\n",
    "Store token-level embeddings natively.\n",
    "Disable indexing to reduce overhead.\n",
    "Run fast retrieval and accurate reranking in one API call.\n",
    "Efficiently scale late interaction.\n",
    "Combining FastEmbed and Qdrant leads to a production-ready pipeline for ColBERT-style reranking without wasting resources. You can do this locally or use Qdrant Cloud. Qdrant offers an easy-to-use API to get started with your search engine, so if you’re ready to dive in, sign up for free at [Qdrant Cloud](https://qdrant.tech/cloud/) and start building."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
