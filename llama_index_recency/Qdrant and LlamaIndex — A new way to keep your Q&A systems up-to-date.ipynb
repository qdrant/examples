{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vvB9_1wRc1Z"
      },
      "source": [
        "Combining Qdrant and LlamaIndex to keep Q&A systems up-to-date\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qdrant/examples/blob/master/multivector-representation/multivector_representation_qdrant.ipynb)\n",
        "\n",
        "#  Introduction\n",
        "\n",
        "Have you ever been frustrated with an answer engine that is stuck in the past? As our world rapidly evolves, the accuracy of information changes accordingly. Traditional models can become outdated, providing answers that were once accurate but are now obsolete. The cost of outdated knowledge can be high - misinforming users, impacting decision-making, and ultimately undermining trust in your system.\n",
        "\n",
        "Qdrant and LlamaIndex work together seamlessly, continually adapting your engine to the relentless pace of information change. By mastering these tools, you can transform your applications from static knowledge repositories into dynamic, adaptable knowledge machines. Whether you're a seasoned data scientist or an AI enthusiast, join us on this learning journey - the future of answer engines is here, and it's time to embrace it.\n",
        "\n",
        "## Learning Outcomes\n",
        "\n",
        "In this tutorial, you will learn the following:\n",
        "\n",
        "- 1️⃣ How to build a question-answering system using LlamaIndex and Qdrant.\n",
        "    - We will load a news dataset, store it with Qdrant client, and load the data into LlamaIndex.\n",
        "- 2️⃣ How to keep the QA engine updated and improve the ranking system.\n",
        "    - We will define two postprocessors: Recency and Cohere Rerank; and use these to create various query engines.\n",
        "- 3️⃣ How to use Node Sources in LlamaIndex to investigate questions and sources on which the answers are based.\n",
        "    - We will query these engines with various questions and compare their responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q5-QRzyRc1a"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Main Tools\n",
        "1. `llama_index`: A powerful tool for building large-scale information retrieval systems. [Learn More](https://gpt-index.readthedocs.io/en/latest/getting_started/starter_example.html)\n",
        "2. `qdrant_client`: A high-performance vector database designed for storing and searching large-scale high-dimensional vectors. In this tutorial, we use Qdrant as our vector storage system.\n",
        "3. `cohere`: A key reranking service to be used in postprocessing. It takes in a query and a list of texts and returns an ordered array with each text assigned a _new_ relevance score.\n",
        "4. `OpenAI`: Important for answer generation, as it takes the top few candidates to produce a final answer.\n",
        "5. `datasets`: Library necessary to import our dataset.\n",
        "6. `pandas`: Relevant library for data manipulation and analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Q5J689Rc1b"
      },
      "source": [
        "### Install Packages\n",
        "\n",
        "Before you start, install the required packages with pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTr0LGRVWvx_"
      },
      "outputs": [],
      "source": [
        "pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0De9P_ARc1b"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index cohere pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4dtHTvnTed7"
      },
      "outputs": [],
      "source": [
        "!pip install -U qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sssKvGNnVI4D"
      },
      "outputs": [],
      "source": [
        "pip install -q cohere llama-index-postprocessor-cohere-rerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-drNRkbV3_J"
      },
      "outputs": [],
      "source": [
        "pip install llama-index-vector-stores-qdrant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3dB3SbJRc1b"
      },
      "source": [
        "Optional: install Rich to make error messages and stack traces easier to read.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Rihws-yRc1b"
      },
      "outputs": [],
      "source": [
        "# !pip install 'rich[jupyter]'\n",
        "%load_ext rich"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uudBIOodRc1c"
      },
      "source": [
        "Import your packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZWsPq7_xRc1c"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from IPython.display import Markdown, display_markdown\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import ServiceContext, SimpleDirectoryReader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E6Fw9BKAVOOa"
      },
      "outputs": [],
      "source": [
        "from llama_index.postprocessor.cohere_rerank import CohereRerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2KT7qYGCVfm0"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.postprocessor import FixedRecencyPostprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JL1q-SF8UiNk"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MKqcohb4Uz09"
      },
      "outputs": [],
      "source": [
        "Path.ls = lambda x: list(x.iterdir())\n",
        "random.seed(42)  # This is the answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosKRjt4Rc1c"
      },
      "source": [
        "### Retrieve API Keys:\n",
        "\n",
        "Before you start, you must retrieve two API keys for the following services:\n",
        "\n",
        "1. OpenAI key for LLM. [Link](https://platform.openai.com/account/api-keys)\n",
        "2. Cohere key for Rerank. [Link](https://dashboard.cohere.ai/api-keys) or additionally, read [Cohere Documentation](https://docs.cohere.com/reference/key).\n",
        "\n",
        "This tutorial by default uses Qdrant Cloud instead, so you need a third key. You can get it [the Qdrant Cloud main control panel](https://cloud.qdrant.io/)   \n",
        "\n",
        "If you are running on Colab, you will need to save your API keys under the secrets section of Colab. Adjust accordingly if you are running the notebook in a different environment.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vy0eonc5TU0-"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ccVf6Ku0Rc1d"
      },
      "outputs": [],
      "source": [
        "def check_environment_keys():\n",
        "    \"\"\"\n",
        "    Utility Function that you have the NECESSARY Keys\n",
        "    \"\"\"\n",
        "    if userdata.get(\"OPENAI_API_KEY\") is None:\n",
        "        raise ValueError(\n",
        "            \"OPENAI_API_KEY cannot be None. Set the key using os.environ['OPENAI_API_KEY']='sk-xxx'\"\n",
        "        )\n",
        "    if userdata.get(\"COHERE_API_KEY\") is None:\n",
        "        raise ValueError(\n",
        "            \"COHERE_API_KEY cannot be None. Set the key using os.environ['COHERE_API_KEY']='xxx'\"\n",
        "        )\n",
        "    if userdata.get(\"QDRANT_API_KEY\") is None:\n",
        "        print(\"[Optional] If you want to use the Qdrant Cloud, please get the Qdrant Cloud API Keys and URL\")\n",
        "\n",
        "\n",
        "check_environment_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dRdDBG_BYfTu"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"COHERE_API_KEY\"] = userdata.get(\"COHERE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4iXd1GeRc1e"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "Our answer engine consists of two main parts:\n",
        "\n",
        "1. Retrieval - Done with Qdrant\n",
        "2. Synthesis - Done with OpenAI API\n",
        "\n",
        "We will use LlamaIndex to make the Query Engine and Qdrant for our Vector Store. Later, we will add components to keep the engine updated and improve ranking after retrieval\n",
        "\n",
        "The arrow point represents the direction of data flow. The \"Query Engine\" box encapsulates the postprocessing step to indicate that it's a part of the query engine's function. This diagram is meant to provide a high-level understanding of the process and does not include all the details involved.\n",
        "\n",
        "![](images/SetupFocus.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6x_f3_ARc1e"
      },
      "source": [
        "# Load Sample Dataset\n",
        "\n",
        "First we need to load our documents. In this example, we will use the [News Category Dataset v3](https://huggingface.co/datasets/heegyu/news-category-dataset). This dataset contains news articles with various fields like `headline`, `category`, `short_description`, `link`, `authors`, and date. Once we load the data, we will reformat it to suit our needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "55c0ed63430f4d2cb271ad8e165e237c",
            "b9bc56fadd1d4eca8d92c4ce1b70c561",
            "d31ea9bff59c41daa347e77c0e949e6e",
            "e202ba7292f8425b83586a91005fe3a1",
            "a4bf159bf18b42f6912672519a850105",
            "5f3d4dd38c044081b7efd4eef8049b26",
            "a7babc8fdcac47d586c7daac8d806912",
            "bccdb0d9778444218f20b5fa11a0c763",
            "76736b2b431f466285e573d6eec4db26",
            "aa8bee9dd00d49659200d5d1a7412caa",
            "ffd2448410354ef1b297c09a18499d2b",
            "b431885e0d8d4d3085a356ddccf9ceab",
            "6bbcdb97b77f44e4ba3b409c39f48539",
            "d90caf3a0e03492ba9b4385dc04bc2c2",
            "e5ab2da13e1c4ffb9ba157dae9ec640a",
            "1fbf2bd2ea044a6688272228d9a58ea6",
            "1f115cef9ff14fd2b9d8748147abb17b",
            "cb9c24805c884f1a9f8d8daefe0bbd97",
            "b562f8cade0649c392d3d1ed1f1e4e80",
            "13aec498cc0b47be8d5bcbd2c67d3fe3",
            "092089012eb241a6ad89f51d5a145834",
            "0b62a66e7d7a4ac791996779ab0da1fa",
            "18dd8524fb9d494eb836ce11943e597c",
            "0e66739a529640e9a8deaa5e097024ac",
            "c00754f809d740ffad864327b15dd99c",
            "8a352abd3f0e47818cfcbf009551b341",
            "2b8dea2d364c4cc7971e288cf8fcaf53",
            "8b7faedf1872440c995a6290538c9e44",
            "d037d2e34e984b3b8a9d6af140502c9f",
            "895d515554bd4eefb86ebc56cdad3250",
            "7519ba8e1e4e49cd875e0a776cba2adb",
            "0c6ecfbc9e0449bf882f7e4c066e64bb",
            "5a33517e83414ce3ad1ee9d56fb301ff"
          ]
        },
        "id": "joKLGFpGRc1e",
        "outputId": "c13a82d9-0398-43c9-85ac-f935f7f9fa93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c0ed63430f4d2cb271ad8e165e237c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/101 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b431885e0d8d4d3085a356ddccf9ceab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data.json:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18dd8524fb9d494eb836ce11943e597c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/209527 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(\"heegyu/news-category-dataset\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "PHxJTTe7Rc1e",
        "outputId": "77eee89a-34bc-44f0-fbe9-164e18b3e7bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a7911533-4f95-4404-8a1b-e75edfd0dcbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>headline</th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Health experts said it is too early to predict...</td>\n",
              "      <td>Carla K. Johnson, AP</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>He was subdued by passengers and crew when he ...</td>\n",
              "      <td>Mary Papenfuss</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>\"Until you have a dog you don't understand wha...</td>\n",
              "      <td>Elyse Wanshel</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
              "      <td>Caroline Bologna</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
              "      <td>Nina Golgowski</td>\n",
              "      <td>2022-09-22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7911533-4f95-4404-8a1b-e75edfd0dcbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7911533-4f95-4404-8a1b-e75edfd0dcbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7911533-4f95-4404-8a1b-e75edfd0dcbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-60607f07-c2b7-430a-b42a-5948a133ec82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60607f07-c2b7-430a-b42a-5948a133ec82')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-60607f07-c2b7-430a-b42a-5948a133ec82 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "\n",
              "                                                link  \\\n",
              "\u001b[1;36m0\u001b[0m  \u001b[4;94mhttps://www.huffpost.com/entry/covid-boosters-...\u001b[0m   \n",
              "\u001b[1;36m1\u001b[0m  \u001b[4;94mhttps://www.huffpost.com/entry/american-airlin...\u001b[0m   \n",
              "\u001b[1;36m2\u001b[0m  \u001b[4;94mhttps://www.huffpost.com/entry/funniest-tweets...\u001b[0m   \n",
              "\u001b[1;36m3\u001b[0m  \u001b[4;94mhttps://www.huffpost.com/entry/funniest-parent...\u001b[0m   \n",
              "\u001b[1;36m4\u001b[0m  \u001b[4;94mhttps://www.huffpost.com/entry/amy-cooper-lose...\u001b[0m   \n",
              "\n",
              "                                            headline   category  \\\n",
              "\u001b[1;36m0\u001b[0m  Over \u001b[1;36m4\u001b[0m Million Americans Roll Up Sleeves For O\u001b[33m...\u001b[0m  U.S. NEWS   \n",
              "\u001b[1;36m1\u001b[0m  American Airlines Flyer Charged, Banned For Li\u001b[33m...\u001b[0m  U.S. NEWS   \n",
              "\u001b[1;36m2\u001b[0m  \u001b[1;36m23\u001b[0m Of The Funniest Tweets About Cats And Dogs \u001b[33m...\u001b[0m     COMEDY   \n",
              "\u001b[1;36m3\u001b[0m  The Funniest Tweets From Parents This Week \u001b[1m(\u001b[0mSe\u001b[33m...\u001b[0m  PARENTING   \n",
              "\u001b[1;36m4\u001b[0m  Woman Who Called Cops On Black Bird-Watcher Lo\u001b[33m...\u001b[0m  U.S. NEWS   \n",
              "\n",
              "                                   short_description               authors  \\\n",
              "\u001b[1;36m0\u001b[0m  Health experts said it is too early to predict\u001b[33m...\u001b[0m  Carla K. Johnson, AP   \n",
              "\u001b[1;36m1\u001b[0m  He was subdued by passengers and crew when he \u001b[33m...\u001b[0m        Mary Papenfuss   \n",
              "\u001b[1;36m2\u001b[0m  \"Until you have a dog you don't understand wha\u001b[33m...\u001b[0m         Elyse Wanshel   \n",
              "\u001b[1;36m3\u001b[0m  \"Accidentally put grown-up toothpaste on my to\u001b[33m...\u001b[0m      Caroline Bologna   \n",
              "\u001b[1;36m4\u001b[0m  Amy Cooper accused investment firm Franklin Te\u001b[33m...\u001b[0m        Nina Golgowski   \n",
              "\n",
              "        date  \n",
              "\u001b[1;36m0\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m23\u001b[0m  \n",
              "\u001b[1;36m1\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m23\u001b[0m  \n",
              "\u001b[1;36m2\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m23\u001b[0m  \n",
              "\u001b[1;36m3\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m23\u001b[0m  \n",
              "\u001b[1;36m4\u001b[0m \u001b[1;36m2022\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m22\u001b[0m  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_single_text(k):\n",
        "    return f\"Under the category:\\n{k['category']}:\\n{k['headline']}\\n{k['short_description']}\"\n",
        "\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFPkxuxhRc1e",
        "outputId": "85ca70e4-94c5-4823-f6e4-0d56a574a707"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-a898c893970a>:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_sampled = df_filtered.groupby(\"year\").apply(sample_func).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "# Assuming `df` is your original dataframe\n",
        "df[\"year\"] = df[\"date\"].dt.year\n",
        "\n",
        "category_columns_to_keep = [\"POLITICS\", \"THE WORLDPOST\", \"WORLD NEWS\", \"WORLDPOST\", \"U.S. NEWS\"]\n",
        "\n",
        "# Filter by category\n",
        "df_filtered = df[df[\"category\"].isin(category_columns_to_keep)]\n",
        "\n",
        "# Sample data for each year\n",
        "\n",
        "\n",
        "def sample_func(x):\n",
        "    return x.sample(min(len(x), 200), random_state=42)\n",
        "\n",
        "\n",
        "df_sampled = df_filtered.groupby(\"year\").apply(sample_func).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "1HWBEURwRc1e",
        "outputId": "76f0866b-e0bb-43a3-efba-dedcf546539d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "\n",
              "year\n",
              "\u001b[1;36m2014\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2015\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2016\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2017\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2018\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2019\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2020\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2021\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "\u001b[1;36m2022\u001b[0m    \u001b[1;36m200\u001b[0m\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sampled[\"year\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ks91Gz_VRc1e"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o12ohKnHRc1e"
      },
      "outputs": [],
      "source": [
        "df = df_sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "pQ-C2_tURc1e",
        "outputId": "a1b13a36-acd9-450d-9260-c2c4b50bc482"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Under the category:\\nWORLDPOST:\\nAfghans Don't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nACLU Seeks To ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nWork and Worth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nJody Hice, Ant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nCapito Wins We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nA Hard-Right R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nHerschel Walke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>Under the category:\\nU.S. NEWS:\\nStocks Fall, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>Under the category:\\nWORLD NEWS:\\nPeru Court O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>Under the category:\\nPOLITICS:\\nMichigan Secre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "\n",
              "\u001b[1;36m0\u001b[0m       Under the category:\\nWORLDPOST:\\nAfghans Don't\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m1\u001b[0m       Under the category:\\nPOLITICS:\\nACLU Seeks To \u001b[33m...\u001b[0m\n",
              "\u001b[1;36m2\u001b[0m       Under the category:\\nPOLITICS:\\nWork and Worth\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m3\u001b[0m       Under the category:\\nPOLITICS:\\nJody Hice, Ant\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m4\u001b[0m       Under the category:\\nPOLITICS:\\nCapito Wins We\u001b[33m...\u001b[0m\n",
              "                              \u001b[33m...\u001b[0m                        \n",
              "\u001b[1;36m1795\u001b[0m    Under the category:\\nPOLITICS:\\nA Hard-Right R\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m1796\u001b[0m    Under the category:\\nPOLITICS:\\nHerschel Walke\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m1797\u001b[0m    Under the category:\\nU.S. NEWS:\\nStocks Fall, \u001b[33m...\u001b[0m\n",
              "\u001b[1;36m1798\u001b[0m    Under the category:\\nWORLD NEWS:\\nPeru Court O\u001b[33m...\u001b[0m\n",
              "\u001b[1;36m1799\u001b[0m    Under the category:\\nPOLITICS:\\nMichigan Secre\u001b[33m...\u001b[0m\n",
              "Name: text, Length: \u001b[1;36m1800\u001b[0m, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text\"] = df.apply(get_single_text, axis=1)\n",
        "df[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LCl5F6CmRc1e",
        "outputId": "6473139a-8400-47eb-cc6d-32c35a19a063"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\u001b[32m\"Under the category:\\nWORLDPOST:\\nFreed Taliban Commander Tells Relative He'll Fight Americans Again\\n\"\u001b[0m"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text\"][9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7qUqN51hRc1e"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=[\"year\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZxZg2NFRc1f"
      },
      "source": [
        "Next, write these documents to text files in a directory. Each document will be written to a text file named after its date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uepvMpFKRc1f",
        "outputId": "a23b0696-c577-4082-f0c8-1d7b3d91d19b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 273 ms, sys: 107 ms, total: 380 ms\n",
            "Wall time: 389 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "write_dir = Path(\"../data/sample\").resolve()\n",
        "if write_dir.exists():\n",
        "    [f.unlink() for f in write_dir.ls()]\n",
        "write_dir.mkdir(exist_ok=True, parents=True)\n",
        "for index, row in df.iterrows():\n",
        "    date = str(row[\"date\"]).replace(\"-\", \"_\")  # replace '-' in date with '_' to avoid issues with file names\n",
        "    file_path = write_dir / f\"date_{date}_row_{index}.txt\"\n",
        "    with file_path.open(\"w\") as f:\n",
        "        f.write(row[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-XH15qiuRc1f"
      },
      "outputs": [],
      "source": [
        "# del dataset, df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnjjgi4IRc1f"
      },
      "source": [
        "## Store Dataset with Qdrant Client\n",
        "We'll be using Qdrant as our vector storage system. Qdrant is a high-performance vector database designed for storing and searching large-scale high-dimensional vectors.\n",
        "\n",
        "### Local Qdrant Server/Docker + Cloud Instructions\n",
        "- If you're running a local Qdrant instance with Docker, use `uri`:\n",
        "  - `uri=\"http://<host>:<port>\"`\n",
        "  \n",
        "Here I'll be using the cloud, so I am using the url set to my cloud instance\n",
        "\n",
        "- Set the API KEY for Qdrant Cloud:\n",
        "  - `api_key=\"<qdrant-api-key>\"`\n",
        "  - `url`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLsUF1XfTkXf",
        "outputId": "11451a48-16b6-467c-edf2-7768a604e196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "collections=[CollectionDescription(name='sample-movies'), CollectionDescription(name='standard-dense-py'), CollectionDescription(name='NewsCategoryv3PoliticsSample'), CollectionDescription(name='_migration_offsets')]\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "client = QdrantClient(\n",
        "    url=\"YOUR_QDRANT_URL\",\n",
        "    api_key=userdata.get(\"QDRANT_API_KEY\"),\n",
        ")\n",
        "\n",
        "print(client.get_collections())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv8C1tSlRc1f"
      },
      "source": [
        "## Load Data into LlamaIndex\n",
        "LlamaIndex has a simple way to load documents from a directory. We can define a function to get the metadata from a file name, and pass this function to the `SimpleDirectoryReader` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vOZjFGRCRc1f"
      },
      "outputs": [],
      "source": [
        "def get_file_metadata(file_name: str):\n",
        "    \"\"\"Get file metadata.\"\"\"\n",
        "    date_str = Path(file_name).stem.split(\"_\")[1:4]\n",
        "    return {\"date\": \"-\".join(date_str)}\n",
        "\n",
        "\n",
        "documents = SimpleDirectoryReader(input_files=write_dir.ls(), file_metadata=get_file_metadata).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qNgx_AK0Rc1f",
        "outputId": "0a68c401-f7d0-47f1-d79e-f05475c59177"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\u001b[1;36m1800\u001b[0m"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBkJODsKRc1f"
      },
      "source": [
        "Let's look at the date ranges in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "565AiBWqRc1f",
        "outputId": "0a8847d2-40a0-43fe-be01-808c89c0f076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-334b20fa50f4>:4: DeprecationWarning: Call to deprecated function (or staticmethod) extra_info. ('extra_info' is deprecated, use 'metadata' instead.) -- Deprecated since version 0.12.2.\n",
            "  dt = datetime.datetime.fromisoformat(document.extra_info[\"date\"])\n"
          ]
        }
      ],
      "source": [
        "dates, years = [], []\n",
        "\n",
        "for document in documents:\n",
        "    dt = datetime.datetime.fromisoformat(document.extra_info[\"date\"])\n",
        "    #     print(d)\n",
        "    try:\n",
        "        dates.append(dt)\n",
        "        years.append(dt.year)\n",
        "    except:\n",
        "        print(dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tpzzHQmRc1f"
      },
      "source": [
        "This `date` key is *necessary* for the Recency Postprocessor that we are going to use later.\n",
        "\n",
        "We have to parse these documents into nodes and create our QdrantVectorStore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2pN1e8bbRc1f",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "\n",
        "# Define settings globally\n",
        "Settings.node_parser = SentenceSplitter(chunk_size=512)\n",
        "\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"NewsCategoryv3PoliticsSample\")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWfNZM-7Rc1f"
      },
      "source": [
        "Next, we will create our `VectorStoreIndex` from the documents. This operation might take some time as it's creating the index from the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B46Dd3LRc1f",
        "outputId": "8fd6917d-22fd-4026-f732-7fbb0b0379f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.53 s, sys: 705 ms, total: 6.23 s\n",
            "Wall time: 22.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "AsWMXo-DrC-U",
        "outputId": "d6a756e3-ee01-4d78-9be8-a25f6b9199cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;35mCollectionsResponse\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mcollections\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mCollectionDescription\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'sample-movies'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mCollectionDescription\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'standard-dense-py'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mCollectionDescription\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'NewsCategoryv3PoliticsSample'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "        \u001b[1;35mCollectionDescription\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'_migration_offsets'\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m\n",
              "\u001b[1m)\u001b[0m"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_collections()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8j9DIXLRc1f"
      },
      "source": [
        "## Run a Test Query\n",
        "\n",
        "We have made an index. But as we saw in the diagram, we also need some added functionality to do 3 things:\n",
        "\n",
        "1. Retrieval\n",
        "    - Convert the text query into embedding\n",
        "    - Find the most similar documents\n",
        "2. Synthesis\n",
        "    - The LLM (here, OpenAI) texts the question, similar documents and a prompt to give you an answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6_X-fXqnRc1g"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHduFLdURc1g",
        "outputId": "bb20f518-9f47-4ad0-9d87-d30e9137a2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The US President is Donald Trump.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"Who is the US President?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh5XmW3qRc1g",
        "outputId": "2b178d8a-60d0-49db-dadc-088c45a7f8bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current US President is Donald Trump.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"Who is the current US President?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUZCKIP1Rc1o"
      },
      "source": [
        "\n",
        "# Adding Postprocessors\n",
        "\n",
        "LlamaIndex excels at composing Retrieval and Ranking steps.\n",
        "\n",
        "The intention behind this is to improve answer quality. Let's see if we can use Postprocessors to improve answer quality by using two approaches:\n",
        "1. Selecting the most recent nodes (Recency).\n",
        "2. Reranking using a different model (Cohere Rerank).\n",
        "\n",
        "![](images/RankFocus.png)\n",
        "\n",
        "Here is what the diagram represents:\n",
        "1. The user issues a query to the query engine.\n",
        "2. The query engine, which has been configured with certain postprocessors, performs a search on the vector store based on the query.\n",
        "3. The query engine then postprocesses the results.\n",
        "4. The postprocessed results are then returned to the user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mkMesKIRc1o"
      },
      "source": [
        "### Define a Recency Postprocessor\n",
        "\n",
        "LlamaIndex allows us to add postprocessors to our query engine. These postprocessors can modify the results of our queries after they are returned from the index. Here, we'll add a recency postprocessor to our query engine. This postprocessor will prioritize recent documents in the results.\n",
        "\n",
        "We'll define a single type of recency postprocessor: `FixedRecencyPostprocessor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GPgDLXorRc1o"
      },
      "outputs": [],
      "source": [
        "recency_postprocessor = FixedRecencyPostprocessor(top_k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEE21GaRc1p"
      },
      "source": [
        "### Rerank with Cohere\n",
        "\n",
        "Cohere Rerank works on the top K results which the Retrieval step from Qdrant returns. While Qdrant works on your entire corpus (here thousands, but Qdrant is designed to work with millions) -- Cohere works with the result from Qdrant. This can improve the search results since it's working on smaller number of entries.\n",
        "\n",
        "![](images/RerankFocus.png)\n",
        "\n",
        "\n",
        "Rerank endpoint takes in a query and a list of texts and produces an ordered array with each text assigned a relevance score. We'll define a `CohereRerank` postprocessor and add it to our query engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mf0_5D-Rc1p"
      },
      "source": [
        "## Defining Query Engines\n",
        "We'll define four query engines for this tutorial:\n",
        "1. Just the Vector Store i.e. Qdrant here\n",
        "1. A recency query engine\n",
        "1. A reranking query engine\n",
        "1. And a combined query engine.\n",
        "\n",
        "The recency query engine uses the `FixedRecencyPostprocessor`, the reranking query engine uses the `CohereRerank` postprocessor, and the combined query engine uses both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Z5nytDCzRc1p"
      },
      "outputs": [],
      "source": [
        "top_k = 10  # set one, reuse from now on, ensures consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hnV9a8F_Rc1p"
      },
      "outputs": [],
      "source": [
        "index_query_engine = index.as_query_engine(\n",
        "    similarity_top_k=top_k,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "l5LeWtuMRc1p"
      },
      "outputs": [],
      "source": [
        "recency_query_engine = index.as_query_engine(\n",
        "    similarity_top_k=top_k,\n",
        "    node_postprocessors=[recency_postprocessor],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RBrkJ_dyRc1p"
      },
      "outputs": [],
      "source": [
        "cohere_rerank = CohereRerank(api_key=os.environ[\"COHERE_API_KEY\"], top_n=top_k)\n",
        "reranking_query_engine = index.as_query_engine(\n",
        "    similarity_top_k=top_k,\n",
        "    node_postprocessors=[cohere_rerank],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BNRWZaW0Rc1p"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=top_k,\n",
        "    node_postprocessors=[cohere_rerank, recency_postprocessor],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atym48MLRc1p"
      },
      "source": [
        "## Querying the Engine\n",
        "Finally, we can query our engine. Let's ask it \"Who is the current US President?\" and see the results from each query engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McazTVorRc1p",
        "outputId": "beac935e-c83b-4eaa-e228-0612a09101d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The US President is Donald Trump.\n"
          ]
        }
      ],
      "source": [
        "# question = \"Who is the current US President?\"\n",
        "response = index_query_engine.query(\"Who is the US President?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaalQ_92Rc1p"
      },
      "source": [
        "The `response` object has a few interesting attributes which help us quickly debug and understand what happened in each of our steps:\n",
        "1. What source nodes (similar to Document Chunks in Langchain) were used to answer the question\n",
        "2. What `extra_info` does the index have which we can use? This could also be sent as a payload to Qdrant to filter on (via epoch time) -- but Llama Index does not\n",
        "\n",
        "Let's unpack that a bit, and we'll use what we learn from `response` to improve our understanding of the query engines and post processors themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd6priQiRc1p"
      },
      "source": [
        "Note that `10` which is the top-k parameter we set. This confirms that we retrieved the 10 documents most similar to the question (or more correct: 10 nearest neighbours to the question) and a confidence score.\n",
        "\n",
        "Can we show this in a more human-readable way?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjK2uS1nRc1p",
        "outputId": "5c0902a6-cf34-41ff-c662-f23fff2c883f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Source (Doc id: c6d27f9b-2df9-4127-9d50-4a28f787489b): Under the category:\n",
            "THE WORLDPOST:\n",
            "World Leaders React To The Reality Of A Trump Presidency\n",
            "Many ...\n",
            "\n",
            "> Source (Doc id: b7ba07bc-ab33-48c7-9d67-ce953328b304): Under the category:\n",
            "POLITICS:\n",
            "Six Bullets\n",
            "We have very little time before the cumulative effect o...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(response.get_formatted_sources()[:318])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xKb0V43Rc1q"
      },
      "source": [
        "Let's check what is stored in the `extra_info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "atAgBIE38Iz-",
        "outputId": "0853d8da-af02-4dae-d9cc-9aa1fb6d9555"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'c6d27f9b-2df9-4127-9d50-4a28f787489b'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2017-01-28 00:00:00'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'b7ba07bc-ab33-48c7-9d67-ce953328b304'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2014-08-21 00:00:00'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'4b06b806-d093-4eef-827f-9a5aa411deb5'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2016-06-24 00:00:00'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'4c199361-5139-4c55-b6b3-d111609c3883'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2018-12-26 00:00:00'\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBI15OEpRc1q"
      },
      "source": [
        "This has a `date` key-value as a string against the `doc id`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0PON9lRc1q"
      },
      "source": [
        "Let's setup some tools to have a question, answer and the responses from the index engine in the same object - this will come handy in a bit for explaining a wrong answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tQYShrNXRc1q"
      },
      "outputs": [],
      "source": [
        "def mprint(text: str):\n",
        "    display_markdown(Markdown(text))\n",
        "\n",
        "\n",
        "class QAInfo:\n",
        "    \"\"\"This class is used to store the question, correct answer and responses from different query engines.\"\"\"\n",
        "\n",
        "    def __init__(self, question: str, correct_answer: str, query_engines: dict[str, Any]):\n",
        "        self.question = question\n",
        "        self.query_engines = query_engines\n",
        "        self.correct_answer = correct_answer\n",
        "        self.responses = {}\n",
        "\n",
        "    def add_response(self, engine: str, response: str):\n",
        "        # This method is used to add the response of a query engine to the responses dictionary.\n",
        "        self.responses[engine] = response\n",
        "\n",
        "    def compare_responses(self):\n",
        "        \"\"\"This function takes in a QAInfo object and a dictionary of query engines, and runs the question through each query engine.\n",
        "        The responses from each engine are added to the QAInfo object.\"\"\"\n",
        "        mprint(f\"### Question: {self.question}\")\n",
        "\n",
        "        for engine_name, engine in query_engines.items():\n",
        "            response = engine.query(self.question)\n",
        "            self.add_response(engine_name, response)\n",
        "            mprint(f\"**{engine_name.title()}**: {response}\")\n",
        "\n",
        "        mprint(f\"Correct Answer is: {self.correct_answer}\")\n",
        "\n",
        "    def node_print(self, index, preview_count=5):\n",
        "        source_nodes = self.responses[index].source_nodes\n",
        "        for i in range(preview_count):\n",
        "            mprint(f\"- {source_nodes[i].node.text}\")\n",
        "\n",
        "\n",
        "query_engines = {\n",
        "    \"qdrant\": index_query_engine,\n",
        "    \"recency\": recency_query_engine,\n",
        "    \"reranking\": reranking_query_engine,\n",
        "    \"both\": query_engine,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "eqjDnP3bRc1q",
        "outputId": "b7ce232c-056c-4e5d-8e39-af2966b381b9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Question: Who is the US President?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Qdrant**: The US President is Donald Trump."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Recency**: The US President is Donald Trump."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Reranking**: Obama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Both**: The US President is Donald Trump."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Correct Answer is: Donald Trump"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question = \"Who is the US President?\"\n",
        "correct_answer = \"Donald Trump\"  # This would normally be determined programmatically.\n",
        "president_qa_info = QAInfo(question=question, correct_answer=correct_answer, query_engines=query_engines)\n",
        "president_qa_info.compare_responses()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "rW-eAOV6Rc1q",
        "outputId": "53634533-2698-4c24-a695-3b9ffaca2357"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Trump Makes Surprise Iraq Visit After Christmas [UPDATED]\n",
              "The commander in chief opted for digital holiday greetings, video conferencing with military members around the globe from the Oval Office."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "president_qa_info.node_print(index=\"recency\", preview_count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "VjjBmGRKRc1q",
        "outputId": "37aac234-946e-4f09-f97f-a0444ea4982a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "THE WORLDPOST:\n",
              "World Leaders React To The Reality Of A Trump Presidency\n",
              "Many of the presidential memorandums and executive decisions will fundamentally affect countries around the globe."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "president_qa_info.node_print(index=\"qdrant\", preview_count=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iHzV_bARc1q"
      },
      "source": [
        "## Impact of how a question is asked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "-ztZ9pKFRc1q",
        "outputId": "8959b4d7-5b67-4a52-b953-91648fb3f907"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Question: Who is US President in 2022?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Qdrant**: Joe Biden"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Recency**: The US President in 2022 is Joe Biden."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Reranking**: Joe Biden"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Both**: The US President in 2022 is Joe Biden."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Correct Answer is: Joe Biden"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question = \"Who is US President in 2022?\"\n",
        "correct_answer = \"Joe Biden\"  # This would normally be determined programmatically.\n",
        "current_president_qa_info = QAInfo(\n",
        "    question=question, correct_answer=correct_answer, query_engines=query_engines\n",
        ")\n",
        "current_president_qa_info.compare_responses()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A314oWDtRc1q"
      },
      "source": [
        "### Investigating for Ranking Challenges\n",
        "\n",
        "We pull the few top documents which from each query engine. To make them easy to read, we've a utility `node_print` here.\n",
        "\n",
        "\n",
        "💡 We notice that Qdrant (using embeddings) correctly pulls out a few mentions of \"2024\", \"Joe Biden\" and \"President Joe Biden\"\n",
        "\n",
        "💡 Cohere also re-orders the top 10 candidates to give the top 3 which mention \"President Joe Biden\".\n",
        "\n",
        "With Recency, we get an undetermined answer. This is because we're only using the one, most recent result.\n",
        "\n",
        "## 🎓 Try this now:\n",
        "\n",
        "> Change the `top_k` value passed to `llama_index` and see how that changes the answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "1_Pg36q7Rc1r",
        "outputId": "dad2322e-61e4-4055-9cb0-0d920657dee0"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Joe Biden Says He 'Can't Picture' U.S. Troops Being In Afghanistan In 2022\n",
              "The president doubled down on his promise to end America's longest-running war at a Thursday press conference, though he said a May 1 deadline seemed unlikely."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "How A Crowded GOP Field Could Bolster A Trump 2024 Campaign\n",
              "As Donald Trump considers another White House run, polls show he's the most popular figure in the Republican Party."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Biden To Give First State Of The Union Address At Fraught Moment\n",
              "President Joe Biden aims to navigate the country out a pandemic, reboot his stalled domestic agenda and confront Russia’s aggression."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "current_president_qa_info.node_print(index=\"qdrant\", preview_count=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "dmBL2OJWRc1r",
        "outputId": "4209d184-c548-4247-8bc9-a99343a75b16"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "How A Crowded GOP Field Could Bolster A Trump 2024 Campaign\n",
              "As Donald Trump considers another White House run, polls show he's the most popular figure in the Republican Party."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "current_president_qa_info.node_print(index=\"recency\", preview_count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "qx2EKqRrRc1r",
        "outputId": "d7414775-671e-4d4f-bbd5-5b67cc54418d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Biden To Give First State Of The Union Address At Fraught Moment\n",
              "President Joe Biden aims to navigate the country out a pandemic, reboot his stalled domestic agenda and confront Russia’s aggression."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "How A Crowded GOP Field Could Bolster A Trump 2024 Campaign\n",
              "As Donald Trump considers another White House run, polls show he's the most popular figure in the Republican Party."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Joe Biden Says He 'Can't Picture' U.S. Troops Being In Afghanistan In 2022\n",
              "The president doubled down on his promise to end America's longest-running war at a Thursday press conference, though he said a May 1 deadline seemed unlikely."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "current_president_qa_info.node_print(index=\"reranking\", preview_count=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ruEdv9Rc1r"
      },
      "source": [
        "## Add a specific Year\n",
        "\n",
        "That looks interesting. Let's try this question after specifying the year:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "S4VaPxs3Rc1r",
        "outputId": "40e263dc-1b18-4127-b2a2-c944e04ebfc9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Question: Who was the US President in 2010?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Qdrant**: Barack Obama was the US President in 2010."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Recency**: Barack Obama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Reranking**: Barack Obama was the US President in 2010."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Both**: Barack Obama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Correct Answer is: Barack Obama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question = \"Who was the US President in 2010?\"\n",
        "correct_answer = \"Barack Obama\"  # This would normally be determined programmatically.\n",
        "president_2010_qa_info = QAInfo(question=question, correct_answer=correct_answer, query_engines=query_engines)\n",
        "president_2010_qa_info.compare_responses()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGYLMD8FRc1r"
      },
      "source": [
        "Let's try a different variant of this question, specify a year and see what happens?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "BPuczn9LRc1r",
        "outputId": "85a0ab1d-43c8-4bfd-8069-58f16cb13fec"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Question: Who was the Finance Minister of India under Manmohan Singh Govt?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Qdrant**: The Finance Minister of India under the Manmohan Singh government was P. Chidambaram."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Recency**: P. Chidambaram"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Reranking**: The Finance Minister of India under the Manmohan Singh government was P. Chidambaram."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Both**: P. Chidambaram"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Correct Answer is: P. Chidambaram"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question = \"Who was the Finance Minister of India under Manmohan Singh Govt?\"\n",
        "correct_answer = \"P. Chidambaram\"  # This would normally be determined programmatically.\n",
        "prime_minister_jan2014 = QAInfo(question=question, correct_answer=correct_answer, query_engines=query_engines)\n",
        "prime_minister_jan2014.compare_responses()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl0T57WVRc1r"
      },
      "source": [
        "### Observation\n",
        "\n",
        "In this question: All the engines give the correct answer!\n",
        "\n",
        "This is despite the fact that the Recency Postprocessor response does not even talk about the Indian Prime Minister! ❌\n",
        "\n",
        "Qdrant via OpenAI Embeddings and Cohere Rerank do not do that much better\n",
        "\n",
        "The correct answer comes from OpenAI LLM's knowledge of the world!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "2Oepco_DRc1r",
        "outputId": "6745c9c6-1ac1-4fc4-8d42-320459ad3280"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "Robbing Main Street to Prop Up Wall Street:  Why Jerry Brown's Rainy Day Fund Is a Bad Idea\n",
              "There is no need to sequester funds urgently needed by Main Street to pay for Wall Street's malfeasance. Californians can have their cake and eat it too - with a state-owned bank."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "WORLDPOST:\n",
              "Cities Need To Get Smarter -- And India's On It"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "WORLD NEWS:\n",
              "Arundhati Roy's New Novel Lays India Bare, Unveiling Worlds Within Our Worlds\n",
              "Malavika Binny, Jawaharlal Nehru University Wearing two hats at once can be an uncomfortable fit, but it does not seem to"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prime_minister_jan2014.node_print(index=\"qdrant\", preview_count=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "42z4j_BWRc1r",
        "outputId": "0a92acd7-9dd1-4545-ecd2-77be391c2c75"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "WORLD NEWS:\n",
              "Arundhati Roy's New Novel Lays India Bare, Unveiling Worlds Within Our Worlds\n",
              "Malavika Binny, Jawaharlal Nehru University Wearing two hats at once can be an uncomfortable fit, but it does not seem to"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prime_minister_jan2014.node_print(index=\"recency\", preview_count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "_4i1m7SwRc1r",
        "outputId": "ab4dd6ec-6fff-467f-e739-8dc09ff778fc"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "WORLDPOST:\n",
              "Cities Need To Get Smarter -- And India's On It"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "WORLD NEWS:\n",
              "Arundhati Roy's New Novel Lays India Bare, Unveiling Worlds Within Our Worlds\n",
              "Malavika Binny, Jawaharlal Nehru University Wearing two hats at once can be an uncomfortable fit, but it does not seem to"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "- Under the category:\n",
              "POLITICS:\n",
              "The World Bank Must Commit to Food Security\n",
              "Much will be said about bringing roads, electricity and infrastructure to underdeveloped regions. But how committed is the World Bank to the planet as a whole when it is doling out its loans?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prime_minister_jan2014.node_print(index=\"reranking\", preview_count=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenhYIMqRc1r"
      },
      "source": [
        "# Recap\n",
        "\n",
        "- 1️⃣ Crafting a Q&A bot with LlamaIndex and Qdrant\n",
        "    - We dumped a news dataset, kicked up a Qdrant client, and stuffed our data into a LlamaIndex\n",
        "- 2️⃣ Keeping our Q&A bot fresh and cranking up the ranking goodness\n",
        "    - We used a recency postprocessor and a Cohere reranking postprocessor, and put them to work building different query engines\n",
        "- 3️⃣ Using Node Sources in Llama Index to dig into the Q&A trails\n",
        "    - We threw a bunch of questions at these engines and saw how they stacked up!\n",
        "\n",
        "We figured out that recency postprocessing has its perks, but it can leave us hanging when we narrow down the info too much. Plugging in a reranking postprocessor like Cohere can help sort the responses better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "092089012eb241a6ad89f51d5a145834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b62a66e7d7a4ac791996779ab0da1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c6ecfbc9e0449bf882f7e4c066e64bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e66739a529640e9a8deaa5e097024ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7faedf1872440c995a6290538c9e44",
            "placeholder": "​",
            "style": "IPY_MODEL_d037d2e34e984b3b8a9d6af140502c9f",
            "value": "Generating train split: 100%"
          }
        },
        "13aec498cc0b47be8d5bcbd2c67d3fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18dd8524fb9d494eb836ce11943e597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e66739a529640e9a8deaa5e097024ac",
              "IPY_MODEL_c00754f809d740ffad864327b15dd99c",
              "IPY_MODEL_8a352abd3f0e47818cfcbf009551b341"
            ],
            "layout": "IPY_MODEL_2b8dea2d364c4cc7971e288cf8fcaf53"
          }
        },
        "1f115cef9ff14fd2b9d8748147abb17b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbf2bd2ea044a6688272228d9a58ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8dea2d364c4cc7971e288cf8fcaf53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c0ed63430f4d2cb271ad8e165e237c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9bc56fadd1d4eca8d92c4ce1b70c561",
              "IPY_MODEL_d31ea9bff59c41daa347e77c0e949e6e",
              "IPY_MODEL_e202ba7292f8425b83586a91005fe3a1"
            ],
            "layout": "IPY_MODEL_a4bf159bf18b42f6912672519a850105"
          }
        },
        "5a33517e83414ce3ad1ee9d56fb301ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f3d4dd38c044081b7efd4eef8049b26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bbcdb97b77f44e4ba3b409c39f48539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f115cef9ff14fd2b9d8748147abb17b",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9c24805c884f1a9f8d8daefe0bbd97",
            "value": "data.json: 100%"
          }
        },
        "7519ba8e1e4e49cd875e0a776cba2adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76736b2b431f466285e573d6eec4db26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "895d515554bd4eefb86ebc56cdad3250": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a352abd3f0e47818cfcbf009551b341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c6ecfbc9e0449bf882f7e4c066e64bb",
            "placeholder": "​",
            "style": "IPY_MODEL_5a33517e83414ce3ad1ee9d56fb301ff",
            "value": " 209527/209527 [00:01&lt;00:00, 105339.51 examples/s]"
          }
        },
        "8b7faedf1872440c995a6290538c9e44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4bf159bf18b42f6912672519a850105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7babc8fdcac47d586c7daac8d806912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa8bee9dd00d49659200d5d1a7412caa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b431885e0d8d4d3085a356ddccf9ceab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bbcdb97b77f44e4ba3b409c39f48539",
              "IPY_MODEL_d90caf3a0e03492ba9b4385dc04bc2c2",
              "IPY_MODEL_e5ab2da13e1c4ffb9ba157dae9ec640a"
            ],
            "layout": "IPY_MODEL_1fbf2bd2ea044a6688272228d9a58ea6"
          }
        },
        "b562f8cade0649c392d3d1ed1f1e4e80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bc56fadd1d4eca8d92c4ce1b70c561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f3d4dd38c044081b7efd4eef8049b26",
            "placeholder": "​",
            "style": "IPY_MODEL_a7babc8fdcac47d586c7daac8d806912",
            "value": "README.md: 100%"
          }
        },
        "bccdb0d9778444218f20b5fa11a0c763": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00754f809d740ffad864327b15dd99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895d515554bd4eefb86ebc56cdad3250",
            "max": 209527,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7519ba8e1e4e49cd875e0a776cba2adb",
            "value": 209527
          }
        },
        "cb9c24805c884f1a9f8d8daefe0bbd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d037d2e34e984b3b8a9d6af140502c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d31ea9bff59c41daa347e77c0e949e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bccdb0d9778444218f20b5fa11a0c763",
            "max": 101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76736b2b431f466285e573d6eec4db26",
            "value": 101
          }
        },
        "d90caf3a0e03492ba9b4385dc04bc2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b562f8cade0649c392d3d1ed1f1e4e80",
            "max": 87295572,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13aec498cc0b47be8d5bcbd2c67d3fe3",
            "value": 87295572
          }
        },
        "e202ba7292f8425b83586a91005fe3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8bee9dd00d49659200d5d1a7412caa",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd2448410354ef1b297c09a18499d2b",
            "value": " 101/101 [00:00&lt;00:00, 2.23kB/s]"
          }
        },
        "e5ab2da13e1c4ffb9ba157dae9ec640a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092089012eb241a6ad89f51d5a145834",
            "placeholder": "​",
            "style": "IPY_MODEL_0b62a66e7d7a4ac791996779ab0da1fa",
            "value": " 87.3M/87.3M [00:00&lt;00:00, 137MB/s]"
          }
        },
        "ffd2448410354ef1b297c09a18499d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
