{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8frpyFJ5DM2J"
   },
   "source": [
    "## Qdrant Essentials: Day 3 - Using Sparse Vectors for Keyword-Based Text Retrieval in Qdrant\n",
    "\n",
    "To interact with Qdrant, we'll install the Qdrant Python client and Qdrant's lightweight embedding library called [FastEmbed](https://github.com/qdrant/fastembed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL9v0A3dElBQ"
   },
   "source": [
    "### Step 1: Install the Qdrant Client & FastEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrkP-XaH7n9C",
    "outputId": "f34514c6-b0a1-45d0-b3c2-76d8c70a8dd8"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"qdrant-client[fastembed]>=1.14.2\"\n",
    "!pip3 install -U -q fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDqScVCnEc69"
   },
   "source": [
    "## Step 2: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdq5RcjfEukp"
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfZGTHu3EtUV"
   },
   "source": [
    "## Step 3: Connect to Qdrant Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpLyGqDd8VWV"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=\"your_url\",\n",
    "    api_key=userdata.get('api-key')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFFistzbbU2f"
   },
   "source": [
    "## Lexical Retrieval with BM25 in Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVja-62eFfGw"
   },
   "source": [
    "The BM25 formula can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\text{BM25}(Q, D) = \\sum_{i=1}^{n} \\text{IDF}(q_i) \\cdot \\mathrm{function}\\left(\\mathrm{TF}(q_i, D),\\, k_1,\\, b,\\, |D|,\\, \\mathrm{avg}_{\\text{corpus}}|D|\\right)\n",
    "$$\n",
    "\n",
    "Qdrant provides tooling to compute IDF on the server side. To enable this, we need to activate the [IDF modifier](https://qdrant.tech/documentation/concepts/indexing/#idf-modifier) when configuring sparse vectors in a collection.\n",
    "\n",
    "> Once enabled, **IDF is maintained at the collection level**.\n",
    "\n",
    "When using any retrieval formula that includes IDF, such as BM25, we no longer need to include the IDF component in the sparse document representations. This leaves us with the following `values` of the documents' words:\n",
    "\n",
    "$$\n",
    "\\text{BM25}(d_i) = \\mathrm{function}\\left(\\mathrm{TF}(d_i, D),\\, k_1,\\, b,\\, |D|,\\, \\mathrm{avg}_{\\text{corpus}}|D|\\right)\n",
    "$$\n",
    "\n",
    "The IDF component will be applied by Qdrant automatically when computing similarity scores.\n",
    "\n",
    "## Step 4: Create a Collection for BM25-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwI9A6Tn-5_H",
    "outputId": "aeb15adf-cda3-42d6-8f49-0359dc91e7c0"
   },
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"bm25_vectors_collection\",\n",
    "    sparse_vectors_config={\n",
    "        \"bm25_sparse_vector\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF #Inverse Document Frequency\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaafhSQHNSqy"
   },
   "source": [
    "## Step 5: Create BM25-based Sparse Vectors with FastEmbed & Insert Them into the Collection\n",
    "\n",
    "The FastEmbed Qdrant library provides a way to [generate BM25 formula-based sparse representations](https://github.com/qdrant/fastembed/blob/main/fastembed/sparse/bm25.py) tailored for Qdrant specifics.\n",
    "\n",
    "The integration between Qdrant and FastEmbed allows you to simply pass your texts and BM25 formula parameters when indexing documents to Qdrant. The conversion to sparse vectors happens under the hood.\n",
    "\n",
    "> **<font color='red'>Update:</font>** Since Qdrant's release [1.15.2](https://github.com/qdrant/qdrant/pull/6891), the conversion to BM25 sparse vectors happens directly in Qdrant, for all supported Qdrant clients.  \n",
    "> Interface-wise, it looks the same as the local inference with FastEmbed, as shown in this notebook. \n",
    "\n",
    "> **Note:** Don’t forget to enable the `IDF` modifier when using BM25-based sparse representations generated by FastEmbed, as they intentionally exclude this component.\n",
    "\n",
    "### BM25 in FastEmbed: Implementation Details\n",
    "\n",
    "**Corpus Average Length**\n",
    "\n",
    "Qdrant and FastEmbed do not compute $\\mathrm{avg}_{\\text{corpus}}|D|$ (the average document length in the corpus). You must **estimate and provide this value** as a BM25 parameter.\n",
    "\n",
    "**Default BM25 Parameters in FastEmbed**\n",
    "\n",
    "- `k = 1.2`\n",
    "- `b = 0.75`\n",
    "\n",
    "**Text Processing Pipeline**\n",
    "\n",
    "FastEmbed uses the [Snowball stemmer](https://www.geeksforgeeks.org/snowball-stemmer-nlp/) to reduce words to their root or base form, and applies language-specific stop word lists (e.g., *and*, *or* in English) to reduce vocabulary size and improve retrieval quality.\n",
    "\n",
    "Therefore, **FastEmbed’s BM25 works out of the box for the following languages**:  \n",
    "*Arabic, Danish, Dutch, English, Finnish, French, German, Greek, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish, Tamil,* and *Turkish*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764,
     "referenced_widgets": [
      "75c89b01d5b24960a4f2db2465986bee",
      "49585ffaf8e14dedb29daab77ce1ef78",
      "7f3a04b157d841278a774a4accc876cf",
      "a74f11b10f30453b90e4380ddce8c0c9",
      "579d8c627e154f7fa3b3a12f356fd08f",
      "5bf7afe8864b44bea269036880ea157c",
      "3f5c733890564deba911ca8cc004c048",
      "ecf9ab85130347d283b06cb8b202328d",
      "a32383626c894fe3a3b6731af0bdace6",
      "c3e89f1c671748b58db801dbede72402",
      "48db385c78d24e8c954fff88daeadfca",
      "1ab196c1a4a04cea9f20aa2f5f98106f",
      "bdd10350f5ee4dcfa8875d0fae383bbd",
      "b3f099d715d947aea42a4c18c1a8bfb5",
      "ad319cb31ed747a2bc4820e697e15189",
      "2bbf695e5776457f9a99a668673a83db",
      "06ede673f7f7405ea83997b1bbc2059d",
      "b1025782593a453187e240510854ed14",
      "5dff7ed32b1d4d11936c9c1fdda9a53c",
      "fcc5b78e709c430a9372bdf30a68512a",
      "f6b1b23a33494ea5b17bda976c47091b",
      "838cf96b44b54a869e64935650d10c66",
      "1a20d1bddb1d47fbaaa34e4d0190ba7c",
      "ec3b12b4a8cc4aa789d9368faee60df4",
      "93b7f140c442484ca4fc055d1a095f7a",
      "31144ddb1ae143a48d024fdacc4b73c6",
      "cece3b5d27194c2dbf2956f8edb0ffc5",
      "eb28778db11b40389c4dac05d2429a11",
      "5ab02ec9f7c94d31931fe008b140a319",
      "bad384c456e94d389196616737accdad",
      "69f5e8b0b50045afae696b8549a68ac8",
      "434eb07d81b14855b908b0c2248ac081",
      "b063ef195804466e9f13a959e6333487",
      "d9accb4561894691ab73fd8723689191",
      "c58547df35484e93a2bbebe20fae8ebc",
      "54b2882b44b340a0b5573e64540ec3b5",
      "736eb57a0c024bb08975f1e3a14762b7",
      "9b17a3c06ff948bba34ce34ed8ed7d77",
      "c4558fe72ec84fe09f27d49edc302cc2",
      "1610fbf6030f48cba803f82b999aed26",
      "628f9b2989c649918374866f12b48ad0",
      "7953d1f7ee344bdd9913548d5a50c9d6",
      "c21ed53274884a37ab52f8defb8b8dcc",
      "65a9574baf504e10b84323f4c434fef3",
      "ac2e5dfc618a433eb7af1a7a6abcffbc",
      "e3c6eea681d446ca969a4d4854549ff1",
      "dc056f94f648444582f1f7ea92cb284c",
      "c5301aed52c44f2f844392512616386a",
      "02938f012c2a4f44bd87802e11294c1d",
      "3c53db0abe1742b4ade45505c06a71c9",
      "49e1dcc87aa041af875e2a2beecf9156",
      "8ba2cd507d4144ed844b07e8754222b3",
      "40d443cf51914115b51ca2c2ae78ed55",
      "830f79109b614c84957f8c3102a12461",
      "4801e8ccd4384fe8b5ecb48edcc1fca7",
      "e288df7010304754a87690409308c883",
      "5bcc33b2271d4afea764f3f80b80cf4e",
      "ee79132d8e604bfd8b1693bbba2430f5",
      "8c71a81fb94e4af4a50c7ea3236850fd",
      "ebe257e22cec46ddb7c9b47b345e858d",
      "53b3d5f7e9be45b28a6d63ebf14b0ddd",
      "ea768921c40646cdb08ea65abfea1599",
      "3384a9fbddb248a8923ecc28c21b62b7",
      "36a217c81cb64d23b92f9883def62677",
      "0dbffae360834926a9a88bf4d7fa0de8",
      "35c18a6f6fe1491c89fa2728814e197a",
      "4ee24647fd274632a08db44439c2ae7f",
      "6311f6ad45f146628427dc04316f5a7c",
      "d75dcae08b4f494aa8d583b4490dfba2",
      "ec7024577b444938a692d0998289d36c",
      "8ac21e2edf8341789dcb77a671e5a947",
      "a6ba58a5362e4cd1bf986dd840ed208c",
      "e8ac56af1781436bae5df68495e6dd72",
      "0fd650c13a22479d9058c0bb42c60e2a",
      "1dfbeefed2d94ca2be6efceba8a809cd",
      "8b94daaff5a2416e82e39a016501bc2f",
      "253cd4a939d54bb5a66af5af9f8992a5",
      "1675005d67ed48f7a08dc8a6f48a014f",
      "3059692cd20646469d179ec7747caa9c",
      "cbeada2657b74826aa5c8fecbc00f8e1",
      "d57e60ab2e304fc69c6b764e95d705af",
      "9b7bfddf402644cc833e0c85b12ec8e7",
      "d1c6d52bbe014d9ba6ebe51b0201bf18",
      "bff46b7ccb2441299fb82d49c9a83f5d",
      "04488896dc0b44e7a01519b313ecdaca",
      "81a8941e1d2346a89d9c1ba325a4815e",
      "4f5ef34c415d49b7b06c9500953182d7",
      "4a8d8318caef4632a4f3d866df776eac",
      "71203a5bbad04619b309030b021fca12",
      "216a862a7b0345d3b6c58d07926bfc26",
      "46451e543f1d42b7afa168e36b2ce579",
      "ea15860524264f738b7d289fd52aec0a",
      "afa1df0c70fc4fa4b6fb485783422e32",
      "8a34e11931d648e7a076c280df575b66",
      "9a594af4c3fd43eebafe140aad27e9e5",
      "3dd11547b5c94a568efd1be5f5f76c46",
      "b82ff82c51004e31b715a9142ca1c161",
      "1793eb29c78b452f9e8ed651506b4bda",
      "03197360376f4c49a744781a13726915",
      "dcdd42bd7a724642af4be2370e94b510",
      "64c6a8e1c2c44c5d88de01ae4bac1343",
      "c1f234a325c04c5983c104af481edcb5",
      "2b78398e3b494092b90f9326e21eae93",
      "8b52d2c379e24a5b99eeee7f52d92d7b",
      "3a18b7917cd4413bb224f98ef1c6fdf9",
      "7d18c332d54446108ce6ae261efe721c",
      "f0b794636a4e4f16835c61a45f1040cf",
      "c8456397212849f1b443849fb0da55f3",
      "63dcc2197a694c0e8a228951fd66b30f",
      "9a82310791e6447ea6875611028e4bca",
      "34904ffea3cb434f983f191c5b6d44cc",
      "b44aea4ff43e456585d45c0b27ca426b",
      "09cfb7037c754a3d9c897ee22dcd9d9d",
      "9fdbb10e025340b09ec56261c19da0ad",
      "8073e87eef574da59e280f659a6b0da6",
      "edee33c1f41e4f8dbc823e308429be3c",
      "256d7555d54d439d866710f472fcf19b",
      "6f053e51d7104a989d949b9934f3d46f",
      "fbb6f6baf1f047eba69ccbfa5bfee64a",
      "82b75dc1b5c8498e8f78dcc8471b8d9f",
      "d2e7b64e4dd44d42b21800b3d382c055",
      "590eb85d0271412694dae6c4787b99b6",
      "e7330103bc58467a9db015fb6f294c9e",
      "350bfb6b56e648a1b3780d641078cc94",
      "5080aa18b92146eaacfec87d25455f97",
      "a86c4258d80548cda5444b6d35f9cd7c",
      "2012a6da1e574e398304ea4b7c1d5f12",
      "d5d7cd16c21447c0b431c4dcedaf609b",
      "32f1d9380a4b4edabc141d948bbe4976",
      "8cd629f634424db39c325b72c34fa8a9",
      "3037af0c82b8499484ab4801240bcd24",
      "9e1fbf05d53349468d34b9d383706e97",
      "9933590c57264ab8a74693a9793ca69e",
      "c4f9058ec3984fd2b5d6a598977dff3f",
      "9d99a94344b54f6aa238e758094fe7ca",
      "af6f957b2e394cf6be834778e2ef970f",
      "8c2c4ed54a594893945bea1b68f5c6df",
      "aeedebeb2357417487a6335b785e173e",
      "ab1da40af1f04062a5def4d1425df675",
      "c3b85876676b4cf3aa4e6347d306a1eb",
      "e50de62f95b04b0f84d44d010c10ded3",
      "984f9c3deaf5479388289939f8e98c8d",
      "985a64ea5bca4266a0bfec9109a97309",
      "129a65811bce4b7e8bc7529fcb18819b",
      "4d1155fae05f44aeacf1639ffe20deb0",
      "405bd671924749d3a8bac44af9ae11a8",
      "78fd1a5c3d41409597f0889ecbb1fbef",
      "1932f9754ba040a7852ca8fb3f9ab15a",
      "13f7dee939cd4faf9dda554b4fd2042e",
      "3f5067fd423f4d69b35feae543284eb1",
      "6bd4554b41ca49cdbca26e2199e8ffea",
      "bcc96d2caa4f4c789dbbff20f2a8e186",
      "3652c93c4d8e469eaba3ebe15515c349",
      "dd763a03d6a2480a99aea8dc96591927",
      "8346fe52b890414f846bbab8e70a05f9",
      "50842e712f2f465b9c8e044a58765dde",
      "6f970870063f40648f114acae51ec529",
      "1ad535af4e114bb4b7d5f8f37a60b822",
      "d9548948074942eb8c388c7f5e2172a3",
      "5266a9554ecb4a76bc2ead39bf54ee4f",
      "c510ce5e423843b1b59a38fd2f345b2a",
      "6b655edbc4c840ca819eb00997587813",
      "3bf2e227a0bf461c84efac11b7ab478b",
      "2bc22939843a4080b92fa574e321cd7b",
      "a6e6dd6330734fd9be20ae5ecbab162c",
      "7d5433d6f6594d6d89e6aedf5f2302bb",
      "1fb80ab8f426407a91cb4f19223357f6",
      "9df8e63890ee483894745e3a7859baa7",
      "59d52e885255471099c1234ecd9df279",
      "a5e2786bee9a48659ba3fb3a5ebcfc4a",
      "dd9f7a88f4ca4b7389630a31981aaeb0",
      "d7ca452993a34cacb067c6ce0b488b01",
      "9a996d831294439b8b75f3bdadb334bb",
      "626e00732780447388ac5ba06bb10706",
      "1a46f6799452474497f9a99f49e9eed1",
      "5e339ca2b4964790ba82da1a8236affd",
      "56cd47b7e83b43c4ba4c5252fe2d8c94",
      "503bb7ef88084986b5149897ce6d8b30",
      "45475ecf24a54787a8f1237f8fe2599f",
      "0410b47eac644b99ab3738ca742fcc4b",
      "7a782f26eea74735a266af76ab48e3bf",
      "25c5fbd305244a1d88cd22a932c5b840",
      "355e4ac4782949af8d06908ea6ac44b7",
      "011b75eab6cc468eac4667fc9117f92c",
      "159a8ee29e36407e87544310db3ebfb0",
      "a8295e11adbe4cf39604562522095f15",
      "deb9e58420244c248d47ebe4b1df23e6",
      "085bf72625a44df197ff2dcfa974bebd",
      "b1f83dbd3a5449c5ba4afae073e816dd",
      "a2d7e92fd44440ed9e324bffbde03dc3",
      "85beaa444bc34ec2b7df80c086fb5eb6",
      "b8e32ea08d5d4e4ca47280449930f74f",
      "947ceba2790f4dcf8c1427c1c8b78722",
      "35e7dccf50bc4963a8ac738794b87771",
      "f27cea5032f140f8ae891e9a7aa15218",
      "2921df4b825c40bfa1ccfec279881e26",
      "f4daba9700dc469c9ff58ad35764a60d",
      "6c90b4eeace34413beded0c80cf7e37e",
      "f786e70cd72b4b6d9e60964f22280b3d",
      "a467f69c82f7487699821fafdb342713",
      "cf5c9362e655439bb3a64788b9c22d7b",
      "3c0b7160a56d4783b1c931a0d77622d0",
      "d2da48e2237d40b3962e3b3f8a98fdc4",
      "71afb9ac9b1949e0a85ddc058d3f3d38",
      "caf0d6a1a92a48d39af26aeea03964f1",
      "0bafeddafa7d478c9c846f7e61607841",
      "1488f13d636549f490173dbf989706da",
      "865f970cb0424021926dea5f602d0713",
      "127ab93a5e4944db89104551b1a74141"
     ]
    },
    "id": "84UMf82UNyw1",
    "outputId": "7171817d-4a05-462d-d9aa-f1fe1ebb66cb"
   },
   "outputs": [],
   "source": [
    "grocery_items_descriptions = [\n",
    "    \"Grated hard cheese\",\n",
    "    \"White crusty bread roll\",\n",
    "    \"Mac and cheese\"\n",
    "]\n",
    "\n",
    "#Estimating the average length of documents in the corpus\n",
    "avg_document_length = sum(len(description.split()) for description in grocery_items_descriptions) / len(grocery_items_descriptions)\n",
    "\n",
    "print(f\"Average document length: {avg_document_length}\")\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=\"bm25_vectors_collection\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            payload={\"text\": description}, #meta data, descriptions text in human-readable format\n",
    "            vector={\n",
    "                \"bm25_sparse_vector\": models.Document( #to run FastEmbed under the hood\n",
    "                    text=description,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                    options={\"avg_len\": avg_document_length} #To pass BM25 parameters, here we're using default k & b for the BM25 formula\n",
    "                )\n",
    "           },\n",
    "        ) for i, description in enumerate(grocery_items_descriptions)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Lfpi-MRc5q"
   },
   "source": [
    "Here, FastEmbed downloads the [Qdrant BM25 model from Hugging Face](https://huggingface.co/Qdrant/bm25) and performs the conversion to Qdrant-compatible sparse representations (so, arrays of `indices` and `values`) under the hood. These vectors are then upserted to Qdrant.\n",
    "\n",
    "In this example, inference - computing sparse representations with FastEmbed - is performed locally, using Google Colab resources.\n",
    "\n",
    "> Qdrant also offers **Cloud Inference** for both sparse and dense vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2k4Ox-Y6C_K"
   },
   "source": [
    "## Step 6: Lexical Retrieval with BM25 & Qdrant\n",
    "\n",
    "Now let's test our BM25-based lexical search in Qdrant.\n",
    "\n",
    "Suppose we're searching for the word **\"cheese\"** — this is our query. Let's break down what happens with this query and the documents indexed to Qdrant in the previous step.\n",
    "\n",
    "#### Step 1\n",
    "\n",
    "For every keyword in the query that is not a stop word in the target language (in our case, English, and **\"cheese\"** is not a stop word):\n",
    "- FastEmbed extracts the **stem** (root/base form) of the word.  \n",
    "  - `\"cheese\"` becomes `\"chees\"`\n",
    "- The stem is then mapped to a corresponding **index** from the vocabulary.  \n",
    "  - `\"chees\"` -> `1496964506`\n",
    "\n",
    "#### Step 2\n",
    "\n",
    "Qdrant lookups up this keyword index (`1496964506`) in the **inverted index**, introduced in the previous video.\n",
    "\n",
    "For every document (found via the inverted index) that contains the keyword `\"cheese\"`, we have the BM25-based score for `\"cheese\"` in that particular document, precomputed by FastEmbed and stored in **Step 5**:\n",
    "\n",
    "$$\n",
    "\\mathrm{function}_{\\text{FastEmbed}}\\left(\\mathrm{TF}(\\text{\"cheese\"}, D),\\, k_1,\\, b,\\, |D|,\\, \\mathrm{avg}_{\\text{corpus}}|D|\\right)\n",
    "$$\n",
    "\n",
    "#### Step 3\n",
    "\n",
    "Qdrant scales this document-specific score by the **IDF** of the keyword `\"cheese\"`, calculated across the entire corpus:\n",
    "\n",
    "$$\n",
    "\\text{IDF}(\\text{\"cheese\"}) \\cdot \\mathrm{function}_{\\text{FastEmbed}}\\left(\\mathrm{TF}(\\text{\"cheese\"}, D),\\, k_1,\\, b,\\, |D|,\\, \\mathrm{avg}_{\\text{corpus}}|D|\\right)\n",
    "$$\n",
    "\n",
    "#### Step 4\n",
    "\n",
    "The final similarity score between the query and a document is the **sum of the scores of all matching keywords**:\n",
    "\n",
    "$$\n",
    "\\text{BM25}(\\text{\"cheese\"}, D) = \\sum_{i=1}^{1} \\text{IDF}(\\text{\"cheese\"}) \\cdot \\mathrm{function}\\left(\\mathrm{TF}(\\text{\"cheese\"}, D),\\, k_1,\\, b,\\, |D|,\\, \\mathrm{avg}_{\\text{corpus}}|D|\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVuqJRZe15pw",
    "outputId": "92820a56-5c71-4634-8a48-eb9f3682b324"
   },
   "outputs": [],
   "source": [
    "client.query_points(\n",
    "    collection_name=\"bm25_vectors_collection\",\n",
    "    using=\"bm25_sparse_vector\",\n",
    "    limit=3,\n",
    "    query=models.Document(  #to run FastEmbed under the hood\n",
    "        text=\"cheese\",\n",
    "        model=\"Qdrant/bm25\"\n",
    "    ),\n",
    "    with_vectors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMw_dtCiYa-s"
   },
   "source": [
    "> BM25 retrieved only the documents that contain the keyword \"*cheese*\", as BM25-based retrieval works strictly with **exact keyword matches**.\n",
    "\n",
    "\n",
    "The description \"*Mac and cheese*\" was ranked higher because the BM25-estimated value of \"*cheese*\" is greater in this text than in \"*Grated hard cheese*\".\n",
    "\n",
    "It's higher because \"*and*\" is a stop word and is excluded from the calculation.  \n",
    "So in \"*Mac and cheese*\", \"*cheese*\" is one of two considered words, whereas in \"*Grated hard cheese*\", it's one of three - giving it lower relative importance.\n",
    "\n",
    "---\n",
    "\n",
    "🎉 Now you know how to use BM25 in Qdrant. This will come in handy when you want to **combine** the precision and explainability of **lexical search** with the flexibility and semantic understanding of **dense vectors** - in a **hybrid search** scenario.\n",
    "\n",
    "But before we dive into hybrid search in Qdrant, let’s explore an approach making keyword-based retrieval semantically aware: **sparse neural retrieval**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-h4d-4MdJCM"
   },
   "source": [
    "## Sparse Neural Retrieval with SPLADE++ in Qdrant\n",
    "\n",
    "Sparse Lexical and Expansion Model (SPLADE) is a family of sparse neural retrievers built on top of [Bidirectional Encoder Representations from Transformers (BERT)](https://huggingface.co/docs/transformers/en/model_doc/bert).\n",
    "\n",
    "> These models are intended for retrieval in **English**, unless fine-tuned or retrained for other languages.\n",
    "\n",
    "In addition to assigning weights to terms in the input text, SPLADE also **expands inputs with contextually relevant terms**. This is done to **solve the vocabulary mismatch problem**, allowing the model to match queries and documents that use different but semantically close terms.\n",
    "\n",
    "ℹ️ Check out more about SPLADE and its architecture in the [\"Modern Sparse Neural Retrieval\" article](https://qdrant.tech/articles/modern-sparse-neural-retrieval).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4TyaK3wgVDX"
   },
   "source": [
    "## Step 7: Create a Collection for Sparse Neural Retrieval with SPLADE++\n",
    "\n",
    "> Note that we’re **not configuring the Inverse Document Frequency (IDF) modifier** here, unlike in BM25-based retrieval. SPLADE models don’t rely on corpus-level statistics like IDF to estimate word relevance. Instead, they generate term weights in sparse representations based on their interactions within the encoded text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fj_j2VwW0Hqy",
    "outputId": "d975be5a-09a2-422b-91bf-436bd8d10daf"
   },
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"splade_vectors_collection\",\n",
    "    sparse_vectors_config={\n",
    "        \"splade_sparse_vector\": models.SparseVectorParams(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ogs_VbehwDlP"
   },
   "source": [
    "## Step 8: Create SPLADE++ Sparse Vectors with FastEmbed & Insert Them into the Collection\n",
    "\n",
    "The FastEmbed library provides **SPLADE++**; one of the latest models in the SPLADE family.\n",
    "\n",
    "> **<font color='red'>Update:</font>** Since the release of [Qdrant Cloud Inference](https://qdrant.tech/blog/qdrant-cloud-inference-launch/), you can move SPLADE++ embedding inference from local execution (as shown in this notebook) to the cloud, reducing latency and centralizing resource usage.\n",
    "\n",
    "As a result, this step looks mostly identical to `Step 5` of this tutorial. However, under the hood, the process of converting a document to a sparse representation is quite different.\n",
    "\n",
    "### Documents to SPLADE++ Sparse Representations\n",
    "\n",
    "SPLADE models generate sparse text representations made up of **tokens** produced by the SPLADE tokenizer.\n",
    "\n",
    "> Tokenizers break text into smaller units called **tokens**, which form the model's **vocabulary**. Depending on the tokenizer, these tokens can be words, subwords, or even characters.\n",
    "\n",
    "> SPLADE models operate on a fixed vocabulary of **30,522 tokens**.\n",
    "\n",
    "#### Text to Tokens\n",
    "\n",
    "Each document is first tokenized and the resulting tokens are mapped to their corresponding indices in the model’s vocabulary.  \n",
    "These indices are then used in the final sparse representation.\n",
    "\n",
    "> You can explore this process in the [Tokenizer Playground](https://huggingface.co/spaces/Xenova/the-tokenizer-playground) by selecting the `custom` tokenizer and entering `Qdrant/Splade_PP_en_v1`.  \n",
    "> For example, \"*cheese*\" is mapped to token index `8808`, and \"*mac*\" to `6097`.\n",
    "\n",
    "#### Weighting Tokens\n",
    "\n",
    "The tokenized text, now represented as token indices, is passed through the SPLADE model.  \n",
    "SPLADE **expands** the input by adding contextually relevant tokens and simultaneously assigns each token in the final sparse representation a **weight** that reflects its role in the text.\n",
    "\n",
    "**SPLADE++ Document Expansion**\n",
    "\n",
    "For example, \"*mac and cheese*\" will be expanded to: \"*mac and cheese dairy apple dish & variety brand food made , foods difference eat restaurant or*\", resulting in a SPLADE-generated sparse representation with **17 non-zero values**.\n",
    "\n",
    "> If you’d like to experiment with SPLADE's expansion behavior, check out our documentation on [using SPLADE in FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-splade/). It includes a utility function to decode SPLADE++ sparse representations back into tokens with their corresponding weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226,
     "referenced_widgets": [
      "19490391afd34431b1a255918ff9c6c0",
      "a3cbe23b932840ce9e443c86a34466f9",
      "ba63b6d0f8394c9ea8e92e72c7bcde0e",
      "2e551f150c514c73b4a1fc0949dfc6c9",
      "e8d8c08ed8dd49e4afbce5fd11f26096",
      "c83a49fa3c8e4f8fb754144fe3d02c61",
      "11c4379e8cb14ba38e675fb85ff8f9f5",
      "a5a637cb4931443980cd14e7cb98a030",
      "5d7faaf199d3456c89ab011a11a6ebbe",
      "14765c57cc9c4e9ca02711e65241de48",
      "8eb30187fcb24b3dae22fd36b07c0648",
      "64d5b1578f6644579e067ea8fd6b70ab",
      "ad373a293ff94ac68b7bfea60a9903ac",
      "c814ddaf206a49f19e94b0d2bba4d433",
      "3cd859d076cd49a4b3f1e4ed44c4c23f",
      "96cd8d0449b14981a420ae4f2334ebf0",
      "c93a73e7582a4d35830a7d86ab2dcd4d",
      "dc561d5d2b1641abb6db196170a1038f",
      "6ff32ab2b2ff4623b46b8908dbc1452c",
      "df935465a70549849157c1d1784ed8e1",
      "f2ec5a81c504433c9574bd07f97cd59f",
      "c4ef5f89c8984455a2b906637bf9534c",
      "638e0542371f48c682eb1441c6dd6467",
      "ad21ad396da8498f991ec7ec34a429ab",
      "0d4e068ce64e45ffa9b95552fc64e770",
      "485aa4d4cc1749ff8097b61a57606b94",
      "004c808b936646cb96b7c09139f200da",
      "717854f8f9bc426cabfb42c434093c82",
      "d79c7e00523a45b4bcd5f668c0c9b86f",
      "a228342fa5124a0bbfebed9eb51919f3",
      "29ca0285ab9b4adcbf3588173cb43819",
      "205e3a87f2674881a7f842ec0d4d48b0",
      "cd220e982529460a9ceec590b190d4d4",
      "44ebf18734d64af3a79b4f7aaeecccce",
      "b384e71c5cfe4256a915f93086e79193",
      "a08f61fa84c94b22b7b6979bee7085a3",
      "26c99fbf2cba4bea9f96722b43253be6",
      "4bf91b19a4564595aab1e17a7cf72a92",
      "020c63d4fe634147a3f93bc9b7c5aa3c",
      "8a955f14532e4da5aee0310dbaa1be4e",
      "e343518e1b5c4fbd8e3cfab5868748bb",
      "b0f3d6f14be74f6ea8152f07129b53ca",
      "6433e92c06734bc7b1ac36924b6aa1de",
      "4b7b02abf8a9456eaed32266acf3be5c",
      "aa175901cc4547368d2e4278afca1b1e",
      "bd48dd07c05f4d83b725688edb2d827d",
      "712c7de18db645b2861aa01b3c274696",
      "18fe4a46f9c04a439070c77d5e2f670d",
      "809e0ed3ef0346b7aa28b5a43918c288",
      "a00fca352ac5482aa68b3e24cd3825a9",
      "ff8b2dc2fac846bc818a85521c3b693d",
      "676ff03617f044c9a6a340910e6ab953",
      "8b84762a9c664df5b3ba06ba658f18aa",
      "1930613f8e8a45f991524bc3a741a297",
      "d6010bb12c0f4b8c968f4fff4ab4fbf3",
      "bfa2421b19164e6092fbe736724205e8",
      "2e58e84bff944fbb97829400c06b50cf",
      "5c448d0125214204a85ea5330dd85568",
      "a2b63e1864ad44499522e76a99747d04",
      "ac729b55fc574f238837429da88b6c6b",
      "e1f8052ab9144f2098e53ebfd17cc612",
      "75a9759247a14fb3ad15a880b1b35a3d",
      "596d08f0f0ba435bbd64b6a4f63ce2f1",
      "12533d48b83c478195f7d394ce207e9c",
      "8106bb7e385b4bd2b050b638446e2bab",
      "5ab7c75fc0e943aeab1688f584561b7b"
     ]
    },
    "id": "M_NSaa9KCeGh",
    "outputId": "ac470d60-0a4d-43b2-9e1d-276f15371816"
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"splade_vectors_collection\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            payload={\"text\": description}, #meta data, descriptions text in human-readable format\n",
    "            vector={\n",
    "                \"splade_sparse_vector\": models.Document( #to run FastEmbed under the hood\n",
    "                    text=description,\n",
    "                    model=\"prithivida/Splade_PP_en_v1\"\n",
    "                )\n",
    "           },\n",
    "        ) for i, description in enumerate(grocery_items_descriptions)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqyCkZT2io5"
   },
   "source": [
    "## Step 9: Sparse Neural Retrieval with SPLADE++ & Qdrant\n",
    "\n",
    "> Conversion of a query to a sparse representation by SPLADE++ works exactly the same way as for documents.\n",
    "\n",
    "Let’s see what sparse neural retrieval brings to the table compared to BM25-based lexical retrieval.\n",
    "\n",
    "We'll test a query where the meaning of the keyword depends heavily on context: \"*a not soft cheese*\". In our toy dataset of grocery item descriptions, the most fitting result should be \"*grated hard cheese*\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWzA8BaN00ds",
    "outputId": "b99a57ea-189a-47fe-aaba-a003cefa35b2"
   },
   "outputs": [],
   "source": [
    "client.query_points(\n",
    "    collection_name=\"splade_vectors_collection\",\n",
    "    using=\"splade_sparse_vector\",\n",
    "    limit=3,\n",
    "    query=models.Document(\n",
    "        text=\"A not soft cheese\",\n",
    "        model=\"prithivida/Splade_PP_en_v1\"\n",
    "    ),\n",
    "    with_vectors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd2KApPbLB9B"
   },
   "source": [
    "Yet for BM25, \"*mac and cheese*\" would be ranked higher, since \"*cheese*\", the only matching keyword between the query and the documents, plays a more prominent role in that description compared to \"*grated hard cheese*\" as we saw in `Step 6`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YENgzt2gjjn7",
    "outputId": "84a9daed-22ec-459d-d410-b7d62a260a84"
   },
   "outputs": [],
   "source": [
    "client.query_points(\n",
    "    collection_name=\"bm25_vectors_collection\",\n",
    "    using=\"bm25_sparse_vector\",\n",
    "    limit=3,\n",
    "    query=models.Document(\n",
    "        text=\"A not soft cheese\",\n",
    "        model=\"Qdrant/bm25\"\n",
    "    ),\n",
    "    with_vectors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP_5wTE7LvFr"
   },
   "source": [
    "### Role of SPLADE++ Document & Query Expansion in Vocabulary Mismatch\n",
    "\n",
    "You may have noticed that SPLADE++ returned a non-zero similarity score between the query \"*A not soft cheese*\" and the document \"*White crusty bread roll*\", even though they have no overlapping keywords.\n",
    "\n",
    "This happened due to SPLADE++’s internal **expansion mechanism**.\n",
    "\n",
    "> SPLADE expands both documents and queries.\n",
    "\n",
    "Let’s now see SPLADE++ in action solving the **vocabulary mismatch** problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hu50lsCY9fM",
    "outputId": "d4c005ab-8331-4f3d-ec82-04e01c1e06cf"
   },
   "outputs": [],
   "source": [
    "client.query_points(\n",
    "    collection_name=\"splade_vectors_collection\",\n",
    "    using=\"splade_sparse_vector\",\n",
    "    limit=3,\n",
    "    query=models.Document(\n",
    "        text=\"parmesan\",\n",
    "        model=\"prithivida/Splade_PP_en_v1\"\n",
    "    ),\n",
    "    with_vectors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9-SFKYrM5ZA"
   },
   "source": [
    "SPLADE expands the query \"*parmesan*\" with 10+ additional tokens, making it possible to match and rank the (also expanded at indexing time) \"*grated hard cheese*\" as the top hit, even though \"*parmesan*\" doesn’t appear in any document in our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-5agFRiwNql"
   },
   "source": [
    "## Qdrant's Sparse Neural Retrievers\n",
    "\n",
    "We’ve been exploring sparse neural retrieval as a promising approach for domains where keyword-based matching is useful, but traditional methods like BM25 fall short due to their lack of semantic understanding.\n",
    "\n",
    "Our goal is to push this field forward by fostering adoption of lightweight, explainable, and practical sparse neural retrievers.\n",
    "\n",
    "To support this, **we’ve developed and open-sourced two custom sparse neural retrievers**, both built on top of the BM25 formula.  \n",
    "You can find all the details in the following articles: [BM42 Sparse Neural Retriever](https://qdrant.tech/articles/bm42/) and [miniCOIL Sparse Neural Retriever](https://qdrant.tech/articles/minicoil/).\n",
    "\n",
    "Both models can be used with FastEmbed and Qdrant in the same way we demonstrated with BM25 and SPLADE++ in this tutorial.\n",
    "\n",
    "- FastEmbed handle for **BM42**: `Qdrant/bm42-all-minilm-l6-v2-attentions`  \n",
    "- FastEmbed handle for **miniCOIL**: `Qdrant/minicoil-v1`\n",
    "\n",
    "> You can check all sparse retrievers supported in FastEmbed using:\n",
    "```python\n",
    "from fastembed import SparseTextEmbedding\n",
    "SparseTextEmbedding.list_supported_models()\n",
    "```\n",
    "\n",
    "🚀 We encourage you to experiment and find the **sparse retriever that fits your data best**!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhGDKPaeQZEt"
   },
   "source": [
    "Congratulations! You’re now well-equipped with everything you need to know about **sparse text retrieval in Qdrant**.\n",
    "\n",
    "This approach shines in domains where exact keyword matches are critical, like e-commerce, medical, legal, and many more.\n",
    "\n",
    "However, sparse (even neural) retrieval has its limits. It’s not so ideal when semantically similar content is expressed in entirely different ways.  \n",
    "Models like SPLADE++ try to close that semantic gap, but doing so makes their representations less sparse and harder to interpret. After all, why \"*apple*\" is related to \"*mac and cheese*\"? 🤔\n",
    "\n",
    "That’s where **dense retrieval** comes in, great for discovery and bridging the vocabulary mismatch natively.\n",
    "\n",
    "So now we have:\n",
    "- **Sparse retrieval**: precise, lightweight, and explainable\n",
    "- **Dense retrieval**: flexible and great for exploration\n",
    "\n",
    "**Why not combine both?** In the next videos, we’ll show you how to do it with **Hybrid Search**.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
