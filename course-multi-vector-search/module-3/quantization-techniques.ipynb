{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-1111-2222-3333-444455556666",
   "metadata": {},
   "source": [
    "# Module 3: Vector Quantization Techniques\n",
    "\n",
    "This notebook demonstrates how to use scalar and binary quantization with multi-vector collections in Qdrant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kffzjhbhqtn",
   "source": "Install the Qdrant client and fastembed libraries.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jlhefhk3mg9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q fastembed qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4viiwvt2g8",
   "source": "Load the ColPali vision-language model for generating multi-vector embeddings from document images.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aqo8t930alu",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import LateInteractionMultimodalEmbedding\n",
    "\n",
    "# Load ColPali model for generating multi-vector embeddings\n",
    "model = LateInteractionMultimodalEmbedding(\n",
    "    model_name=\"Qdrant/colpali-v1.3-fp16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pb82liq20jh",
   "source": "Embed sample document images. Each image produces 1030 vectors of 128 dimensions  -  1024 image patches plus 6 instruction tokens.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06lr2go5hobo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for document images...\n",
      "Generated embeddings for 4 documents\n",
      "Each document has 1030 vectors of dimension 128\n"
     ]
    }
   ],
   "source": [
    "# Sample document images for our collection\n",
    "# We'll use images from the course materials\n",
    "image_paths = [\n",
    "    \"images/financial-report.png\",\n",
    "    \"images/titanic-newspaper.jpg\",\n",
    "    \"images/men-walk-on-moon-newspaper.jpg\",\n",
    "    \"images/einstein-newspaper.jpg\",\n",
    "]\n",
    "\n",
    "# Metadata for each document\n",
    "documents = [\n",
    "    {\"title\": \"Financial Report\", \"type\": \"report\", \"topic\": \"finance\"},\n",
    "    {\"title\": \"Titanic Sinking\", \"type\": \"newspaper\", \"topic\": \"history\"},\n",
    "    {\"title\": \"Moon Landing\", \"type\": \"newspaper\", \"topic\": \"space\"},\n",
    "    {\"title\": \"Einstein Theory\", \"type\": \"newspaper\", \"topic\": \"science\"},\n",
    "]\n",
    "\n",
    "# Generate embeddings for all images\n",
    "print(\"Generating embeddings for document images...\")\n",
    "image_embeddings = list(model.embed_image(image_paths))\n",
    "print(f\"Generated embeddings for {len(image_embeddings)} documents\")\n",
    "print(f\"Each document has {image_embeddings[0].shape[0]} vectors of dimension {image_embeddings[0].shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6-1111-2222-3333-444455556668",
   "metadata": {},
   "source": [
    "## Scalar Quantization\n",
    "\n",
    "Scalar quantization converts float32 values to 8-bit integers (uint8), reducing memory by **4x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e5f6a7-1111-2222-3333-444455556669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Delete collections if they exist (for clean reruns)\n",
    "client.delete_collection(\"colpali-scalar\", timeout=60)\n",
    "client.delete_collection(\"colpali-binary\", timeout=60)\n",
    "\n",
    "# Create collection with scalar quantization (4x compression)\n",
    "client.create_collection(\n",
    "    collection_name=\"colpali-scalar\",\n",
    "    vectors_config={\n",
    "        \"colpali\": models.VectorParams(\n",
    "            size=128,  # ColPali embedding dimension\n",
    "            distance=models.Distance.DOT,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),  # Disable HNSW for multi-vector\n",
    "        ),\n",
    "    },\n",
    "    quantization_config=models.ScalarQuantization(\n",
    "        scalar=models.ScalarQuantizationConfig(\n",
    "            type=models.ScalarType.INT8,\n",
    "            quantile=0.99,  # Exclude 1% outliers for better scaling\n",
    "            always_ram=True,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d72829-4e02-4c47-9e10-660f1916cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'colpali-scalar' has 4 points\n",
      "Quantization: scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=0.99, always_ram=True)\n"
     ]
    }
   ],
   "source": [
    "# Ingest data into the scalar-quantized collection\n",
    "client.upsert(\n",
    "    collection_name=\"colpali-scalar\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector={\"colpali\": embedding.tolist()},\n",
    "            payload=documents[i],\n",
    "        )\n",
    "        for i, embedding in enumerate(image_embeddings)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Verify the data was ingested\n",
    "collection_info = client.get_collection(\"colpali-scalar\")\n",
    "print(f\"Collection 'colpali-scalar' has {collection_info.points_count} points\")\n",
    "print(f\"Quantization: {collection_info.config.quantization_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-1111-2222-3333-444455556670",
   "metadata": {},
   "source": [
    "## Binary Quantization\n",
    "\n",
    "Binary quantization represents each component as a single bit (positive/negative), achieving **32x compression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a7b8c9-1111-2222-3333-444455556671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create collection with binary quantization (32x compression)\n",
    "client.create_collection(\n",
    "    collection_name=\"colpali-binary\",\n",
    "    vectors_config={\n",
    "        \"colpali\": models.VectorParams(\n",
    "            size=128,  # ColPali embedding dimension\n",
    "            distance=models.Distance.DOT,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),  # Disable HNSW for multi-vector\n",
    "        ),\n",
    "    },\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(\n",
    "            always_ram=True,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c913f1e-1571-40ce-b818-6312ff3fc2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'colpali-binary' has 4 points\n",
      "Quantization: binary=BinaryQuantizationConfig(always_ram=True, encoding=None, query_encoding=None)\n"
     ]
    }
   ],
   "source": [
    "# Ingest the same data into the binary-quantized collection\n",
    "client.upsert(\n",
    "    collection_name=\"colpali-binary\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector={\"colpali\": embedding.tolist()},\n",
    "            payload=documents[i],\n",
    "        )\n",
    "        for i, embedding in enumerate(image_embeddings)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Verify the data was ingested\n",
    "collection_info = client.get_collection(\"colpali-binary\")\n",
    "print(f\"Collection 'colpali-binary' has {collection_info.points_count} points\")\n",
    "print(f\"Quantization: {collection_info.config.quantization_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-1111-2222-3333-444455556672",
   "metadata": {},
   "source": [
    "## Search with Rescoring\n",
    "\n",
    "Qdrant provides automatic rescoring: the quantized index quickly finds candidates, then re-ranks them using the original float32 vectors for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c9d0e1-1111-2222-3333-444455556673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 18 vectors of dimension 128\n"
     ]
    }
   ],
   "source": [
    "# Generate query embeddings from a text query\n",
    "query = \"financial quarterly results revenue\"\n",
    "query_embeddings = list(model.embed_text([query]))[0]\n",
    "print(f\"Query has {query_embeddings.shape[0]} vectors of dimension {query_embeddings.shape[1]}\")\n",
    "\n",
    "# Search with rescoring enabled (default behavior)\n",
    "results = client.query_points(\n",
    "    collection_name=\"colpali-scalar\",\n",
    "    query=query_embeddings.tolist(),\n",
    "    using=\"colpali\",\n",
    "    limit=10,\n",
    "    search_params=models.SearchParams(\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,       # Use quantized vectors for initial search\n",
    "            rescore=True,       # Re-rank with original float32 vectors\n",
    "            oversampling=2.0,   # Fetch 2x candidates before rescoring\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf28903-d8cc-482f-9bd8-e7f22da0fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results from scalar-quantized collection:\n",
      "--------------------------------------------------\n",
      "Score: 12.5780 | Financial Report (finance)\n",
      "Score: 6.7059 | Moon Landing (space)\n",
      "Score: 6.4723 | Einstein Theory (science)\n",
      "Score: 5.2878 | Titanic Sinking (history)\n"
     ]
    }
   ],
   "source": [
    "# Display search results from scalar-quantized collection\n",
    "print(\"Search results from scalar-quantized collection:\")\n",
    "print(\"-\" * 50)\n",
    "for point in results.points:\n",
    "    print(f\"Score: {point.score:.4f} | {point.payload['title']} ({point.payload['topic']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d0e1f2-1111-2222-3333-444455556674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results from binary-quantized collection:\n",
      "--------------------------------------------------\n",
      "Score: 12.5780 | Financial Report (finance)\n",
      "Score: 6.7059 | Moon Landing (space)\n",
      "Score: 6.4723 | Einstein Theory (science)\n",
      "Score: 5.2878 | Titanic Sinking (history)\n"
     ]
    }
   ],
   "source": [
    "# Compare results from binary-quantized collection\n",
    "results_binary = client.query_points(\n",
    "    collection_name=\"colpali-binary\",\n",
    "    query=query_embeddings.tolist(),\n",
    "    using=\"colpali\",\n",
    "    limit=10,\n",
    "    search_params=models.SearchParams(\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,\n",
    "            rescore=True,\n",
    "            oversampling=2.0,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Search results from binary-quantized collection:\")\n",
    "print(\"-\" * 50)\n",
    "for point in results_binary.points:\n",
    "    print(f\"Score: {point.score:.4f} | {point.payload['title']} ({point.payload['topic']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fwmdr0i1r8k",
   "metadata": {},
   "source": [
    "## Impact of Rescoring\n",
    "\n",
    "Let's compare results with and without rescoring to see the impact on result quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eluzgo38pvn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary quantization WITHOUT rescoring:\n",
      "--------------------------------------------------\n",
      "Score: 12.5780 | Financial Report (finance)\n",
      "Score: 6.7059 | Moon Landing (space)\n",
      "Score: 6.4723 | Einstein Theory (science)\n",
      "Score: 5.2878 | Titanic Sinking (history)\n",
      "\n",
      "\n",
      "Binary quantization WITH rescoring (from earlier):\n",
      "--------------------------------------------------\n",
      "Score: 12.5780 | Financial Report (finance)\n",
      "Score: 6.7059 | Moon Landing (space)\n",
      "Score: 6.4723 | Einstein Theory (science)\n",
      "Score: 5.2878 | Titanic Sinking (history)\n"
     ]
    }
   ],
   "source": [
    "# Search WITHOUT rescoring (uses only quantized vectors)\n",
    "results_no_rescore = client.query_points(\n",
    "    collection_name=\"colpali-binary\",\n",
    "    query=query_embeddings.tolist(),\n",
    "    using=\"colpali\",\n",
    "    limit=10,\n",
    "    search_params=models.SearchParams(\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,\n",
    "            rescore=False,  # Disabled: results come from quantized vectors only\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Binary quantization WITHOUT rescoring:\")\n",
    "print(\"-\" * 50)\n",
    "for point in results_no_rescore.points:\n",
    "    print(f\"Score: {point.score:.4f} | {point.payload['title']} ({point.payload['topic']})\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Binary quantization WITH rescoring (from earlier):\")\n",
    "print(\"-\" * 50)\n",
    "for point in results_binary.points:\n",
    "    print(f\"Score: {point.score:.4f} | {point.payload['title']} ({point.payload['topic']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
