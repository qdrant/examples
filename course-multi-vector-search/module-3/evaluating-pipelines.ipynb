{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-intro",
   "metadata": {},
   "source": [
    "# Module 3: Evaluating Search Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q fastembed qdrant-client ranx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qrels-intro",
   "metadata": {},
   "source": [
    "## Ground Truth (Qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qrels-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth: which documents are relevant to which queries?\n",
    "# We'll use our 4 sample images and create meaningful queries\n",
    "qrels_dict = {\n",
    "    \"company quarterly financial results and revenue\": {\n",
    "        \"images/financial-report.png\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"historic ship disaster at sea\": {\n",
    "        \"images/titanic-newspaper.jpg\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"space exploration and astronauts\": {\n",
    "        \"images/men-walk-on-moon-newspaper.jpg\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"physics theory and scientist\": {\n",
    "        \"images/einstein-newspaper.jpg\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"news headline from early 1900s\": {\n",
    "        \"images/titanic-newspaper.jpg\": 3,  # Highly relevant\n",
    "        \"images/einstein-newspaper.jpg\": 2,  # Somewhat relevant\n",
    "    },\n",
    "    \"business earnings report\": {\n",
    "        \"images/financial-report.png\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"NASA moon landing mission\": {\n",
    "        \"images/men-walk-on-moon-newspaper.jpg\": 3,  # Highly relevant\n",
    "    },\n",
    "    \"ocean liner sinking\": {\n",
    "        \"images/titanic-newspaper.jpg\": 3,  # Highly relevant\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collection-arch",
   "metadata": {},
   "source": [
    "## Collection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "create-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection 'eval-multi-vector' with 4 named vector configurations\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import (\n",
    "    VectorParams, Distance, MultiVectorConfig, MultiVectorComparator,\n",
    "    ScalarQuantization, ScalarQuantizationConfig, ScalarType,\n",
    ")\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "COLLECTION_NAME = \"eval-multi-vector\"\n",
    "\n",
    "# Delete collection if it exists (for clean reruns)\n",
    "client.delete_collection(COLLECTION_NAME, timeout=60)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        # Full ColModernVBERT multi-vector (no quantization)\n",
    "        \"colmodernvbert\": VectorParams(\n",
    "            size=128,\n",
    "            distance=Distance.DOT,\n",
    "            multivector_config=MultiVectorConfig(\n",
    "                comparator=MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),  # Disable HNSW for multi-vector\n",
    "        ),\n",
    "        # ColModernVBERT with scalar quantization enabled\n",
    "        \"colmodernvbert_sq\": VectorParams(\n",
    "            size=128,\n",
    "            distance=Distance.DOT,\n",
    "            multivector_config=MultiVectorConfig(\n",
    "                comparator=MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),\n",
    "            quantization_config=ScalarQuantization(\n",
    "                scalar=ScalarQuantizationConfig(\n",
    "                    type=ScalarType.INT8,\n",
    "                    quantile=0.99,\n",
    "                    always_ram=True,\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        # MUVERA single-vector approximation for fast HNSW search\n",
    "        \"muvera\": VectorParams(\n",
    "            size=40960,  # muvera.embedding_size from k_sim=6, dim_proj=32, r_reps=20\n",
    "            distance=Distance.COSINE,\n",
    "        ),\n",
    "        # Hierarchical pooled multi-vector (k=32 clusters)\n",
    "        \"hierarchical\": VectorParams(\n",
    "            size=128,\n",
    "            distance=Distance.DOT,\n",
    "            multivector_config=MultiVectorConfig(\n",
    "                comparator=MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Created collection '{COLLECTION_NAME}' with 4 named vector configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-section",
   "metadata": {},
   "source": [
    "## Load Models and Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load-models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColModernVBERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69dca3154cc405a91a07cfdc249475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffc2b55507449b087fa86da3e33f3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MUVERA...\n",
      "MUVERA embedding size: 40960\n"
     ]
    }
   ],
   "source": [
    "from fastembed import LateInteractionMultimodalEmbedding\n",
    "from fastembed.postprocess import Muvera\n",
    "from scipy.cluster.vq import kmeans2\n",
    "import numpy as np\n",
    "\n",
    "# Load the embedding model\n",
    "print(\"Loading ColModernVBERT model...\")\n",
    "model = LateInteractionMultimodalEmbedding(\n",
    "    model_name=\"Qdrant/colmodernvbert\"\n",
    ")\n",
    "\n",
    "# Initialize MUVERA with same configuration as the collection\n",
    "print(\"Initializing MUVERA...\")\n",
    "muvera = Muvera.from_multivector_model(model=model, k_sim=6, dim_proj=32, r_reps=20)\n",
    "\n",
    "print(f\"MUVERA embedding size: {muvera.embedding_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r0pm979uohq",
   "metadata": {},
   "source": [
    "Define a helper to pool multi-vector embeddings into k centroids using k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_pool(embeddings: np.ndarray, k: int = 32) -> np.ndarray:\n",
    "    \"\"\"Pool multi-vector to k centroids using k-means clustering.\"\"\"\n",
    "    if len(embeddings) <= k:\n",
    "        return embeddings  # No pooling needed\n",
    "    centroids, labels = kmeans2(embeddings.astype(np.float64), k, minit=\"++\")\n",
    "    # Return mean of embeddings in each cluster\n",
    "    pooled = np.array([\n",
    "        embeddings[labels == i].mean(axis=0)\n",
    "        for i in range(k)\n",
    "        if (labels == i).any()\n",
    "    ])\n",
    "    return pooled.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nqr4qo5g9m",
   "metadata": {},
   "source": [
    "Define the ingestion pipeline that generates all four vector representations (full multi-vector, scalar-quantized, MUVERA, and hierarchical-pooled) and uploads them as a single point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2968dd9-6f3c-4895-84fc-bcbeb6615f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_upload_document(doc_path: str, doc_id: int) -> None:\n",
    "    \"\"\"Embed a document and upload all four vector representations.\"\"\"\n",
    "    # Generate full multi-vector embeddings\n",
    "    full_multivec = np.array(list(model.embed_image([doc_path]))[0])\n",
    "    \n",
    "    print(f\"  Document {doc_id}: {doc_path}\")\n",
    "    print(f\"    Full multi-vector shape: {full_multivec.shape}\")\n",
    "\n",
    "    # Generate MUVERA approximation\n",
    "    muvera_vec = muvera.process_document(full_multivec)\n",
    "    print(f\"    MUVERA vector shape: {muvera_vec.shape}\")\n",
    "\n",
    "    # Generate hierarchical pooled version (k=32)\n",
    "    hierarchical_vec = hierarchical_pool(full_multivec, k=32)\n",
    "    print(f\"    Hierarchical pooled shape: {hierarchical_vec.shape}\")\n",
    "\n",
    "    # Upload all representations in one point\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=doc_id,\n",
    "                payload={\"filename\": doc_path},\n",
    "                vector={\n",
    "                    \"colmodernvbert\": full_multivec.tolist(),\n",
    "                    \"colmodernvbert_sq\": full_multivec.tolist(),  # Same data, quantized config\n",
    "                    \"muvera\": muvera_vec.tolist(),\n",
    "                    \"hierarchical\": hierarchical_vec.tolist(),\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ingest-section",
   "metadata": {},
   "source": [
    "## Ingest Sample Documents\n",
    "\n",
    "We'll use the 4 sample images and generate all 4 vector representations for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ingest-docs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding and uploading documents...\n",
      "\n",
      "  Document 0: images/financial-report.png\n",
      "    Full multi-vector shape: (884, 128)\n",
      "    MUVERA vector shape: (40960,)\n",
      "    Hierarchical pooled shape: (32, 128)\n",
      "\n",
      "  Document 1: images/titanic-newspaper.jpg\n",
      "    Full multi-vector shape: (1149, 128)\n",
      "    MUVERA vector shape: (40960,)\n",
      "    Hierarchical pooled shape: (32, 128)\n",
      "\n",
      "  Document 2: images/men-walk-on-moon-newspaper.jpg\n",
      "    Full multi-vector shape: (1149, 128)\n",
      "    MUVERA vector shape: (40960,)\n",
      "    Hierarchical pooled shape: (32, 128)\n",
      "\n",
      "  Document 3: images/einstein-newspaper.jpg\n",
      "    Full multi-vector shape: (1149, 128)\n",
      "    MUVERA vector shape: (40960,)\n",
      "    Hierarchical pooled shape: (32, 128)\n",
      "\n",
      "\n",
      "Collection 'eval-multi-vector' now has 4 points\n"
     ]
    }
   ],
   "source": [
    "# Document paths - our sample dataset\n",
    "DOC_PATHS = [\n",
    "    \"images/financial-report.png\",\n",
    "    \"images/titanic-newspaper.jpg\",\n",
    "    \"images/men-walk-on-moon-newspaper.jpg\",\n",
    "    \"images/einstein-newspaper.jpg\",\n",
    "]\n",
    "\n",
    "# Upload all documents with all 4 vector representations\n",
    "print(\"Embedding and uploading documents...\\n\")\n",
    "for doc_id, doc_path in enumerate(DOC_PATHS):\n",
    "    embed_and_upload_document(doc_path, doc_id)\n",
    "    print()\n",
    "\n",
    "# Verify ingestion\n",
    "collection_info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nCollection '{COLLECTION_NAME}' now has {collection_info.points_count} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-section",
   "metadata": {},
   "source": [
    "## Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pipeline-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 6 pipeline configurations\n"
     ]
    }
   ],
   "source": [
    "PIPELINES = {\n",
    "    # Baseline: full quality, no optimization\n",
    "    \"baseline\": {\n",
    "        \"using\": \"colmodernvbert\",\n",
    "        \"prefetch_using\": None,\n",
    "    },\n",
    "\n",
    "    # Scalar quantized: reduced memory, minimal quality loss\n",
    "    \"scalar_quantized\": {\n",
    "        \"using\": \"colmodernvbert_sq\",\n",
    "        \"prefetch_using\": None,\n",
    "    },\n",
    "\n",
    "    # Hierarchical pooling: fewer vectors per document\n",
    "    \"hierarchical\": {\n",
    "        \"using\": \"hierarchical\",\n",
    "        \"prefetch_using\": None,\n",
    "    },\n",
    "\n",
    "    # Two-stage: fast MUVERA prefetch + full quality rerank\n",
    "    \"muvera_rerank\": {\n",
    "        \"using\": \"colmodernvbert\",\n",
    "        \"prefetch_using\": \"muvera\",\n",
    "        \"prefetch_limit\": 50,\n",
    "    },\n",
    "\n",
    "    # Two-stage with quantized rerank\n",
    "    \"muvera_quantized\": {\n",
    "        \"using\": \"colmodernvbert_sq\",\n",
    "        \"prefetch_using\": \"muvera\",\n",
    "        \"prefetch_limit\": 50,\n",
    "    },\n",
    "\n",
    "    # Maximum compression: MUVERA prefetch + pooled rerank\n",
    "    \"muvera_hierarchical\": {\n",
    "        \"using\": \"hierarchical\",\n",
    "        \"prefetch_using\": \"muvera\",\n",
    "        \"prefetch_limit\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(PIPELINES)} pipeline configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-section",
   "metadata": {},
   "source": [
    "## Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "search-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pipeline(\n",
    "    query_embedding: np.ndarray,\n",
    "    using: str,\n",
    "    prefetch_using: str | None = None,\n",
    "    prefetch_limit: int = 50,\n",
    "    limit: int = 10,\n",
    ") -> list[tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Execute a search pipeline with optional prefetch stage.\n",
    "\n",
    "    Args:\n",
    "        query_embedding: The query's multi-vector embedding\n",
    "        using: Named vector for final ranking\n",
    "        prefetch_using: Named vector for prefetch (None = single-stage)\n",
    "        prefetch_limit: How many candidates to retrieve in prefetch\n",
    "        limit: Final number of results\n",
    "\n",
    "    Returns:\n",
    "        List of (filename, score) tuples\n",
    "    \"\"\"\n",
    "    if prefetch_using is None:\n",
    "        # Single-stage search\n",
    "        response = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=query_embedding.tolist(),\n",
    "            using=using,\n",
    "            limit=limit,\n",
    "        )\n",
    "    else:\n",
    "        # Two-stage search: prefetch with one vector, rerank with another\n",
    "        # For MUVERA prefetch, we need the MUVERA query embedding\n",
    "        if prefetch_using == \"muvera\":\n",
    "            prefetch_query = muvera.process_query(query_embedding).tolist()\n",
    "        else:\n",
    "            prefetch_query = query_embedding.tolist()\n",
    "\n",
    "        response = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            prefetch=[\n",
    "                models.Prefetch(\n",
    "                    query=prefetch_query,\n",
    "                    using=prefetch_using,\n",
    "                    limit=prefetch_limit,\n",
    "                )\n",
    "            ],\n",
    "            query=query_embedding.tolist(),\n",
    "            using=using,\n",
    "            limit=limit,\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        (point.payload[\"filename\"], point.score)\n",
    "        for point in response.points\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embed-queries-section",
   "metadata": {},
   "source": [
    "## Embed Queries\n",
    "\n",
    "Generate embeddings for all evaluation queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "embed-queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 8 queries...\n",
      "  'company quarterly financial results and ...' -> shape (18, 128)\n",
      "  'historic ship disaster at sea...' -> shape (17, 128)\n",
      "  'space exploration and astronauts...' -> shape (17, 128)\n",
      "  'physics theory and scientist...' -> shape (17, 128)\n",
      "  'news headline from early 1900s...' -> shape (18, 128)\n",
      "  'business earnings report...' -> shape (15, 128)\n",
      "  'NASA moon landing mission...' -> shape (17, 128)\n",
      "  'ocean liner sinking...' -> shape (16, 128)\n",
      "\n",
      "Embedded 8 queries\n"
     ]
    }
   ],
   "source": [
    "# Get all unique queries from qrels\n",
    "QUERIES = list(qrels_dict.keys())\n",
    "\n",
    "print(f\"Embedding {len(QUERIES)} queries...\")\n",
    "\n",
    "# Generate embeddings for all queries\n",
    "query_embeddings = {}\n",
    "for query in QUERIES:\n",
    "    embedding = np.array(list(model.embed_text([query]))[0])\n",
    "    query_embeddings[query] = embedding\n",
    "    print(f\"  '{query[:40]}...' -> shape {embedding.shape}\")\n",
    "\n",
    "print(f\"\\nEmbedded {len(query_embeddings)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-search-section",
   "metadata": {},
   "source": [
    "## Test Search Pipelines\n",
    "\n",
    "Let's test a single query with each pipeline to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "test-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'company quarterly financial results and revenue'\n",
      "\n",
      "Expected: images/financial-report.png (relevance=3)\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "baseline:\n",
      "  10.3651 | images/financial-report.png\n",
      "  6.4249 | images/einstein-newspaper.jpg\n",
      "  6.3433 | images/titanic-newspaper.jpg\n",
      "  6.2661 | images/men-walk-on-moon-newspaper.jpg\n",
      "\n",
      "scalar_quantized:\n",
      "  10.3651 | images/financial-report.png\n",
      "  6.4249 | images/einstein-newspaper.jpg\n",
      "  6.3433 | images/titanic-newspaper.jpg\n",
      "  6.2661 | images/men-walk-on-moon-newspaper.jpg\n",
      "\n",
      "hierarchical:\n",
      "  7.2940 | images/financial-report.png\n",
      "  3.6461 | images/men-walk-on-moon-newspaper.jpg\n",
      "  2.6607 | images/einstein-newspaper.jpg\n",
      "  1.9426 | images/titanic-newspaper.jpg\n",
      "\n",
      "muvera_rerank:\n",
      "  10.3651 | images/financial-report.png\n",
      "  6.4249 | images/einstein-newspaper.jpg\n",
      "  6.3433 | images/titanic-newspaper.jpg\n",
      "  6.2661 | images/men-walk-on-moon-newspaper.jpg\n",
      "\n",
      "muvera_quantized:\n",
      "  10.3651 | images/financial-report.png\n",
      "  6.4249 | images/einstein-newspaper.jpg\n",
      "  6.3433 | images/titanic-newspaper.jpg\n",
      "  6.2661 | images/men-walk-on-moon-newspaper.jpg\n",
      "\n",
      "muvera_hierarchical:\n",
      "  7.2940 | images/financial-report.png\n",
      "  3.6461 | images/men-walk-on-moon-newspaper.jpg\n",
      "  2.6607 | images/einstein-newspaper.jpg\n",
      "  1.9426 | images/titanic-newspaper.jpg\n"
     ]
    }
   ],
   "source": [
    "test_query = \"company quarterly financial results and revenue\"\n",
    "test_embedding = query_embeddings[test_query]\n",
    "\n",
    "print(f\"Query: '{test_query}'\\n\")\n",
    "print(\"Expected: images/financial-report.png (relevance=3)\\n\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for pipeline_name, config in PIPELINES.items():\n",
    "    results = search_pipeline(test_embedding, **config, limit=4)\n",
    "    print(f\"\\n{pipeline_name}:\")\n",
    "    for filename, score in results:\n",
    "        print(f\"  {score:.4f} | {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "run-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline...\n",
      "  Avg latency: 12.37 ms\n",
      "Evaluating scalar_quantized...\n",
      "  Avg latency: 11.12 ms\n",
      "Evaluating hierarchical...\n",
      "  Avg latency: 10.58 ms\n",
      "Evaluating muvera_rerank...\n",
      "  Avg latency: 78.48 ms\n",
      "Evaluating muvera_quantized...\n",
      "  Avg latency: 83.82 ms\n",
      "Evaluating muvera_hierarchical...\n",
      "  Avg latency: 77.97 ms\n",
      "\n",
      "All pipelines evaluated!\n"
     ]
    }
   ],
   "source": [
    "from ranx import Qrels, Run, compare\n",
    "import time\n",
    "\n",
    "# Create ranx Qrels object from our ground truth\n",
    "qrels = Qrels(qrels_dict)\n",
    "\n",
    "# Collect runs from each pipeline\n",
    "runs = []\n",
    "latency_results = {}\n",
    "\n",
    "for pipeline_name, config in PIPELINES.items():\n",
    "    print(f\"Evaluating {pipeline_name}...\")\n",
    "    pipeline_results = {}\n",
    "    latencies = []\n",
    "\n",
    "    for query_text, query_embedding in query_embeddings.items():\n",
    "        start = time.perf_counter()\n",
    "        search_results = search_pipeline(query_embedding, **config, limit=10)\n",
    "        latencies.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "        # Convert to ranx format: {doc_id: score}\n",
    "        pipeline_results[query_text] = {\n",
    "            filename: score for filename, score in search_results\n",
    "        }\n",
    "\n",
    "    runs.append(Run(pipeline_results, name=pipeline_name))\n",
    "    latency_results[pipeline_name] = np.mean(latencies)\n",
    "    print(f\"  Avg latency: {latency_results[pipeline_name]:.2f} ms\")\n",
    "\n",
    "print(\"\\nAll pipelines evaluated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-section",
   "metadata": {},
   "source": [
    "## Compare All Pipelines\n",
    "\n",
    "ranx provides a convenient `compare` function that shows metrics side-by-side with statistical significance indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compare-pipelines",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#    Model                  NDCG@10    Recall@10    MRR\n",
      "---  -------------------  ---------  -----------  -----\n",
      "a    baseline                 0.894            1  0.854\n",
      "b    scalar_quantized         0.894            1  0.854\n",
      "c    hierarchical             0.956            1  0.938\n",
      "d    muvera_rerank            0.894            1  0.854\n",
      "e    muvera_quantized         0.894            1  0.854\n",
      "f    muvera_hierarchical      0.956            1  0.938\n"
     ]
    }
   ],
   "source": [
    "# Compare all pipelines\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=[\"ndcg@10\", \"recall@10\", \"mrr\"],\n",
    "    max_p=0.05,  # Statistical significance threshold\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latency-section",
   "metadata": {},
   "source": [
    "## Latency Results\n",
    "\n",
    "Let's also look at the latency measurements for each pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "show-latency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Query Latency (ms)\n",
      "----------------------------------------\n",
      "hierarchical                 10.58 ms\n",
      "scalar_quantized             11.12 ms\n",
      "baseline                     12.37 ms\n",
      "muvera_hierarchical          77.97 ms\n",
      "muvera_rerank                78.48 ms\n",
      "muvera_quantized             83.82 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Query Latency (ms)\")\n",
    "print(\"-\" * 40)\n",
    "for pipeline_name, latency in sorted(latency_results.items(), key=lambda x: x[1]):\n",
    "    print(f\"{pipeline_name:25} {latency:8.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-cell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
