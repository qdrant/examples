{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616ed32b-38b0-4e81-a528-f4cb1f1602d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Module 3: Pooling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1pv25ldga6",
   "metadata": {},
   "source": [
    "Load the ColPali model for generating multi-vector image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6115fc-3051-4b0f-9737-832d68727b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61be4ca6691740118bc36fdde6faed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3721a909194eada812487ab60f1b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastembed import LateInteractionMultimodalEmbedding\n",
    "\n",
    "# Load ColPali model\n",
    "model = LateInteractionMultimodalEmbedding(\n",
    "    model_name=\"Qdrant/colpali-v1.3-fp16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdcvk2bfhf4",
   "metadata": {},
   "source": [
    "**Spatial pooling**: reshape the 1024 patch embeddings into a 32×32 grid and average along rows or columns. This reduces 1024 vectors to just 32, achieving a 32× memory reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2c9710-f5d7-466d-802a-d0f741b6d015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1030, 128)\n",
      "Original: 263,680 bytes (257 KB)\n",
      "Row pooled: 8,192 bytes (8 KB)\n",
      "Reduction: 32×\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Embed a document image (returns 1024 patches × 128 dimensions)\n",
    "image_path = \"images/financial-report.png\"  # Your document image\n",
    "embeddings = list(model.embed_image([image_path]))[0]\n",
    "print(f\"Original shape: {embeddings.shape}\")  # (1024, 128)\n",
    "\n",
    "# Reshape to spatial grid: (rows, columns, embedding_dim)\n",
    "# Get only the first 1024 embeddings, as instruction tokens do\n",
    "# not represent images\n",
    "grid = embeddings[:1024].reshape(32, 32, 128)\n",
    "\n",
    "# Row pooling: average across columns (axis=1)\n",
    "row_pooled = grid.mean(axis=1)  # Shape: (32, 128)\n",
    "\n",
    "# Column pooling: average across rows (axis=0)\n",
    "col_pooled = grid.mean(axis=0)  # Shape: (32, 128)\n",
    "\n",
    "# Combined approach (optional): concatenate row and column pooled\n",
    "combined = np.vstack([row_pooled, col_pooled])  # Shape: (64, 128)\n",
    "\n",
    "# Memory comparison\n",
    "original_memory = embeddings.nbytes  # 1024 × 128 × 4 = 524,288 bytes\n",
    "pooled_memory = row_pooled.nbytes    # 32 × 128 × 4 = 16,384 bytes\n",
    "\n",
    "print(f\"Original: {original_memory:,} bytes ({original_memory // 1024} KB)\")\n",
    "print(f\"Row pooled: {pooled_memory:,} bytes ({pooled_memory // 1024} KB)\")\n",
    "print(f\"Reduction: {original_memory // pooled_memory}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7v3uxknjxmr",
   "metadata": {},
   "source": [
    "**Hierarchical pooling**: use k-means clustering to group similar patch embeddings, then average within each cluster. This approach is content-aware and lets you choose any compression ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e8cc33-b934-4a9d-912e-5a5c6064df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 16: 1030 → 16 vectors (64× reduction)\n",
      "k= 32: 1030 → 32 vectors (32× reduction)\n",
      "k= 64: 1030 → 64 vectors (16× reduction)\n",
      "k=128: 1030 → 128 vectors (8× reduction)\n"
     ]
    }
   ],
   "source": [
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "# Embed a document image\n",
    "image_path = \"images/financial-report.png\"\n",
    "embeddings = list(model.embed_image([image_path]))[0]\n",
    "\n",
    "def hierarchical_pool(embeddings: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Pool embeddings using k-means clustering.\"\"\"\n",
    "    # Cluster embeddings into k groups\n",
    "    # kmeans2 supports only float32, so we need to convert the embeddings\n",
    "    centroids, labels = kmeans2(embeddings.astype(np.float32), k, minit='++')\n",
    "\n",
    "    # Pool within each cluster using mean\n",
    "    pooled = np.array([\n",
    "        embeddings[labels == i].mean(axis=0)\n",
    "        for i in range(k)\n",
    "    ])\n",
    "    return pooled\n",
    "\n",
    "# Compare different compression levels\n",
    "for k in [16, 32, 64, 128]:\n",
    "    pooled = hierarchical_pool(embeddings, k)\n",
    "    reduction = len(embeddings) / k\n",
    "    print(f\"k={k:3d}: {len(embeddings)} → {k} vectors ({reduction:.0f}× reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ee7ef-a2f7-4ce2-b98b-8bf38ab922cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
