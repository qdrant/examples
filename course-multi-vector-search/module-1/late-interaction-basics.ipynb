{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebe879db87a4432",
   "metadata": {},
   "source": [
    "# Module 1: Late Interaction Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9p5pv2oh9",
   "source": "Define a simple query and two documents to compare how different embedding approaches represent them.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396986ed-a976-41a0-aad3-6de8f2406c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Qdrant is an AI-native vector database and a semantic search engine\",\n",
    "    \"Relational databases are not well-suited for search\",\n",
    "]\n",
    "query = \"What is Qdrant?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11591ce2-f88c-438d-9594-beb4d7cff0bb",
   "metadata": {},
   "source": [
    "## Single-Vector Embeddings (No Interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54183c0-4a75-4981-a06c-3f1bc14b6b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Load the BAAI/bge-small-en-v1.5 model\n",
    "dense_model = TextEmbedding(\"BAAI/bge-small-en-v1.5\")\n",
    "# Pass the documents through the model. The .passage_embed \n",
    "# method returns a generator we can iterate over and is \n",
    "# supposed to be used for the documents only.\n",
    "dense_generator = dense_model.passage_embed(documents)\n",
    "# Running next on the generator yields one vector at\n",
    "# the time, representing a single document.\n",
    "dense_vector = next(dense_generator)\n",
    "dense_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f340ad-8ba3-4572-84ee-6171cdf5aa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dense vector for the query as well, using \n",
    "# the .query_embed method this time.\n",
    "dense_query_vector = next(dense_model.query_embed(query))\n",
    "dense_query_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wxe4h2vwnue",
   "source": "Compute dot product similarity between the query and each document. Higher scores indicate stronger semantic matches.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7416f7b-c2d1-4642-b3b6-a5df3549a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6554835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the dot product between the query\n",
    "# and the first document vector\n",
    "np.dot(dense_query_vector, dense_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zgkv6yd2r4",
   "source": "Now compare the same query against the second document.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bada239c-dc12-47d5-8923-407452cb7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43436375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the dot product between the same query\n",
    "# and the second document vectors\n",
    "np.dot(dense_query_vector, next(dense_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811caba5-69d2-45bc-9552-5aeac7adf37b",
   "metadata": {},
   "source": [
    "## Cross-Encoders (Early Interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e995ba5b-ebd4-49e1-b06f-69f0cdd9052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.133832931518555, -11.428644180297852]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed.rerank.cross_encoder import TextCrossEncoder\n",
    "\n",
    "# Load the Xenova/ms-marco-MiniLM-L-6-v2 cross encoder model\n",
    "cross_encoder = TextCrossEncoder(\"Xenova/ms-marco-MiniLM-L-6-v2\")\n",
    "# Run .rerank method on the query and all the documents.\n",
    "# It does not create any vector representations, but gives\n",
    "# the score indicating the relevance of the document for\n",
    "# the provided query.\n",
    "score_generator = cross_encoder.rerank(query, documents)\n",
    "list(score_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c154200-a65c-4f47-bc97-e0d092d2623f",
   "metadata": {},
   "source": [
    "## Late Interaction: The Core Paradigm\n",
    "\n",
    "### The ColBERT Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c39129-3acb-4876-ba07-5cda22f00bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import LateInteractionTextEmbedding\n",
    "\n",
    "# Load the colbert-ir/colbertv2.0 model\n",
    "colbert_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n",
    "# Run .passage_embed on all the documents and create\n",
    "# a generator of the multi-vector representations\n",
    "colbert_generator = colbert_model.passage_embed(documents)\n",
    "colbert_vector = next(colbert_generator)\n",
    "colbert_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f88562d-deef-4ce5-a448-0c854742521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create multi-vector representation for the query\n",
    "colbert_query_vector = next(colbert_model.query_embed(query))\n",
    "colbert_query_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768b8df-75a0-4c66-a5d9-5c7be934af0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}