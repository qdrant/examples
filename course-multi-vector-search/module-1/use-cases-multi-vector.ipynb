{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d7cbab-7355-4118-83da-b81a073ea865",
   "metadata": {},
   "source": [
    "# Module 1: Use Cases for Multi-Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miqzkiuodid",
   "source": "Define a specific technical query about Python database connection pool exhaustion in async web applications.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ef7cb7-ae75-463a-b7b1-753f36cceffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I prevent Python database connection \" \\\n",
    "        \"pool exhaustion in async web applications?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o2rqpcd7ol",
   "source": "Define four candidate documents with varying relevance levels  -  from highly relevant to keyword-stuffed to completely irrelevant.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77deb3f-29f0-40ed-975b-1cbb34ef53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    # Document A: Highly relevant - addresses all query aspects\n",
    "    \"When async tasks fail to return database connections, the pool \"\n",
    "    \"becomes exhausted and requests start failing. Ensuring \"\n",
    "    \"connections are closed after awaits prevents this.\",\n",
    "\n",
    "    # Document B: Partially relevant - mentions some concepts\n",
    "    \"Database resource exhaustion can occur due to limited pool sizes.\",\n",
    "\n",
    "    # Document C: Keyword-stuffed - contains related terms without substance\n",
    "    \"Understanding concurrency, async IO, and database performance in \"\n",
    "    \"Python web applications.\",\n",
    "\n",
    "    # Document D: Completely irrelevant\n",
    "    \"Handling training for pythons should be done gradually, starting \"\n",
    "    \"with short sessions and increasing duration as the snake becomes \"\n",
    "    \"more comfortable.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rflgr5uqv1",
   "source": "Load a single-vector embedding model (BGE) to establish a baseline for comparison.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f0cfa2-578e-4069-90b4-21b1eb36998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Load the BAAI/bge-small-en-v1.5 model\n",
    "dense_model = TextEmbedding(\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gzg923wccl",
   "source": "Embed the query as a single 384-dimensional vector.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eafc809-113c-4d6b-97d4-9011d078041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_query_vector = next(dense_model.query_embed(query))\n",
    "dense_query_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqje5ugdzhn",
   "source": "Embed all documents as single vectors for batch comparison.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa4ecd3-e4f0-415e-be40-f0474438e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dense_vectors = np.array(list(dense_model.passage_embed(documents)))\n",
    "dense_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6n326uskume",
   "source": "Compute dot product similarities. Notice that the keyword-stuffed Document C scores higher than the genuinely relevant Document A with single-vector search.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f963ae-89f4-4fcc-a1b1-429de784db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85484755, 0.76778555, 0.86039245, 0.5341173 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(dense_query_vector, dense_vectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gb3v2supsbr",
   "source": "Now load ColBERT, a late interaction model that produces per-token embeddings instead of a single vector.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38db1089-7add-4515-9835-38ced625cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import LateInteractionTextEmbedding\n",
    "\n",
    "# Load the colbert-ir/colbertv2.0 model\n",
    "colbert_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ypzrsc0hyal",
   "source": "Embed the query as a multi-vector representation  -  one 128-dimensional vector per token.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f845e04a-05ca-4e4e-8e86-327618c49aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colbert_query_vector = next(colbert_model.query_embed(query))\n",
    "colbert_query_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3t2ndetogaj",
   "source": "Embed documents as multi-vectors. Each document gets a different number of vectors depending on its token count.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2261cb09-0dda-4377-94c1-6653bb51e596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 128), (13, 128), (16, 128), (25, 128)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colbert_vectors = list(colbert_model.passage_embed(documents))\n",
    "[cv.shape for cv in colbert_vectors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oul9vwr75jo",
   "source": "Compute MaxSim scores. Unlike single-vector search, ColBERT correctly ranks Document A highest because it matches the query at the token level.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6b2b06-fa42-4b4f-b5d2-a22e7e54c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.181477\n",
      "16.222866\n",
      "14.829226\n",
      "10.377555\n"
     ]
    }
   ],
   "source": [
    "for colbert_doc_vector in colbert_vectors:\n",
    "    # For each document, compute similarity between all query-doc token pairs\n",
    "    dot_product = np.dot(colbert_query_vector, colbert_doc_vector.T)\n",
    "    # For each query token, take the maximum similarity with any doc token\n",
    "    max_scores = dot_product.max(axis=1)\n",
    "    # Sum these maximum similarities to get the final MaxSim score\n",
    "    print(max_scores.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fd017-f87d-470b-adbc-33fcd6be7f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
